<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_n1gqd67us0zz-3.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-3 0}.lst-kix_7tb268x5qth-0>li{counter-increment:lst-ctn-kix_7tb268x5qth-0}ol.lst-kix_om4jn8q1pf5n-1.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-1 0}ol.lst-kix_2wxk5sk3ailv-5.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-5 0}ol.lst-kix_7tb268x5qth-8.start{counter-reset:lst-ctn-kix_7tb268x5qth-8 0}ol.lst-kix_n1gqd67us0zz-0{list-style-type:none}ol.lst-kix_b110zvjx6803-2.start{counter-reset:lst-ctn-kix_b110zvjx6803-2 0}ol.lst-kix_n1gqd67us0zz-1{list-style-type:none}ol.lst-kix_n1gqd67us0zz-2{list-style-type:none}.lst-kix_2wxk5sk3ailv-2>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-2}ol.lst-kix_n1gqd67us0zz-3{list-style-type:none}ol.lst-kix_n1gqd67us0zz-4{list-style-type:none}ol.lst-kix_b110zvjx6803-8.start{counter-reset:lst-ctn-kix_b110zvjx6803-8 0}ol.lst-kix_n1gqd67us0zz-5{list-style-type:none}ol.lst-kix_n1gqd67us0zz-6{list-style-type:none}ol.lst-kix_n1gqd67us0zz-7{list-style-type:none}ol.lst-kix_n1gqd67us0zz-8{list-style-type:none}.lst-kix_om4jn8q1pf5n-3>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-3}.lst-kix_lhffz7nho2oz-6>li:before{content:"\0025cf   "}.lst-kix_lhffz7nho2oz-5>li:before{content:"\0025a0   "}.lst-kix_lhffz7nho2oz-7>li:before{content:"\0025cb   "}ol.lst-kix_om4jn8q1pf5n-7.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-7 0}.lst-kix_lhffz7nho2oz-4>li:before{content:"\0025cb   "}.lst-kix_lhffz7nho2oz-8>li:before{content:"\0025a0   "}ol.lst-kix_2wxk5sk3ailv-0.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-0 0}.lst-kix_7tb268x5qth-2>li{counter-increment:lst-ctn-kix_7tb268x5qth-2}.lst-kix_lhffz7nho2oz-0>li:before{content:"\0025cf   "}.lst-kix_lhffz7nho2oz-2>li:before{content:"\0025a0   "}.lst-kix_om4jn8q1pf5n-5>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-5}.lst-kix_n1gqd67us0zz-1>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-1}.lst-kix_lhffz7nho2oz-1>li:before{content:"\0025cb   "}.lst-kix_lhffz7nho2oz-3>li:before{content:"\0025cf   "}.lst-kix_b110zvjx6803-0>li{counter-increment:lst-ctn-kix_b110zvjx6803-0}.lst-kix_om4jn8q1pf5n-1>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-1}.lst-kix_dbv9dzfh4djb-8>li:before{content:"\0025cf   "}.lst-kix_om4jn8q1pf5n-7>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-7}ol.lst-kix_b110zvjx6803-7.start{counter-reset:lst-ctn-kix_b110zvjx6803-7 0}.lst-kix_ivmur5kk55ke-0>li:before{content:"\002794   "}.lst-kix_dbv9dzfh4djb-4>li:before{content:"\0025c6   "}.lst-kix_dbv9dzfh4djb-5>li:before{content:"\0025cf   "}ul.lst-kix_2wxk5sk3ailv-1{list-style-type:none}.lst-kix_ivmur5kk55ke-1>li:before{content:"\0025c6   "}.lst-kix_dbv9dzfh4djb-3>li:before{content:"\0025cb   "}.lst-kix_dbv9dzfh4djb-7>li:before{content:"\0025c6   "}ol.lst-kix_7tb268x5qth-2.start{counter-reset:lst-ctn-kix_7tb268x5qth-2 0}ol.lst-kix_om4jn8q1pf5n-2.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-2 0}.lst-kix_ivmur5kk55ke-3>li:before{content:"\0025cb   "}.lst-kix_ivmur5kk55ke-4>li:before{content:"\0025c6   "}.lst-kix_ivmur5kk55ke-2>li:before{content:"\0025cf   "}.lst-kix_dbv9dzfh4djb-6>li:before{content:"\0025cb   "}.lst-kix_n1gqd67us0zz-6>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-6}.lst-kix_dbv9dzfh4djb-0>li:before{content:"\002794   "}.lst-kix_dbv9dzfh4djb-1>li:before{content:"\0025c6   "}.lst-kix_b110zvjx6803-2>li{counter-increment:lst-ctn-kix_b110zvjx6803-2}ol.lst-kix_7tb268x5qth-3.start{counter-reset:lst-ctn-kix_7tb268x5qth-3 0}ol.lst-kix_2wxk5sk3ailv-4.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-4 0}.lst-kix_n1gqd67us0zz-3>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-3}.lst-kix_dbv9dzfh4djb-2>li:before{content:"\0025cf   "}ol.lst-kix_b110zvjx6803-1.start{counter-reset:lst-ctn-kix_b110zvjx6803-1 0}.lst-kix_2wxk5sk3ailv-4>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-4}.lst-kix_n1gqd67us0zz-5>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-5}.lst-kix_p9gl7kquprfc-6>li:before{content:"\0025cf   "}.lst-kix_b110zvjx6803-6>li:before{content:"(" counter(lst-ctn-kix_b110zvjx6803-6,lower-roman) ") "}.lst-kix_b110zvjx6803-2>li:before{content:"" counter(lst-ctn-kix_b110zvjx6803-2,decimal) ". "}ol.lst-kix_7tb268x5qth-4.start{counter-reset:lst-ctn-kix_7tb268x5qth-4 0}.lst-kix_b110zvjx6803-0>li:before{content:"" counter(lst-ctn-kix_b110zvjx6803-0,upper-roman) ". "}.lst-kix_p9gl7kquprfc-4>li:before{content:"\0025cb   "}.lst-kix_b110zvjx6803-8>li:before{content:"(" counter(lst-ctn-kix_b110zvjx6803-8,lower-roman) ") "}ul.lst-kix_kw8utb3obtvt-8{list-style-type:none}ul.lst-kix_kw8utb3obtvt-7{list-style-type:none}ul.lst-kix_kw8utb3obtvt-6{list-style-type:none}ol.lst-kix_b110zvjx6803-0{list-style-type:none}ol.lst-kix_b110zvjx6803-1{list-style-type:none}ul.lst-kix_kw8utb3obtvt-1{list-style-type:none}ol.lst-kix_b110zvjx6803-2{list-style-type:none}ul.lst-kix_kw8utb3obtvt-0{list-style-type:none}.lst-kix_p9gl7kquprfc-2>li:before{content:"\0025a0   "}ol.lst-kix_b110zvjx6803-3{list-style-type:none}ol.lst-kix_b110zvjx6803-4{list-style-type:none}ol.lst-kix_b110zvjx6803-5{list-style-type:none}ul.lst-kix_kw8utb3obtvt-5{list-style-type:none}ol.lst-kix_b110zvjx6803-6{list-style-type:none}ul.lst-kix_kw8utb3obtvt-4{list-style-type:none}.lst-kix_p9gl7kquprfc-0>li:before{content:"\0025cf   "}ol.lst-kix_b110zvjx6803-7{list-style-type:none}ul.lst-kix_kw8utb3obtvt-3{list-style-type:none}ol.lst-kix_b110zvjx6803-8{list-style-type:none}.lst-kix_7tb268x5qth-6>li{counter-increment:lst-ctn-kix_7tb268x5qth-6}ul.lst-kix_kw8utb3obtvt-2{list-style-type:none}.lst-kix_b110zvjx6803-4>li:before{content:"(" counter(lst-ctn-kix_b110zvjx6803-4,decimal) ") "}.lst-kix_2wxk5sk3ailv-6>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-6,decimal) ". "}.lst-kix_n1gqd67us0zz-5>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-5,lower-roman) ". "}.lst-kix_n1gqd67us0zz-7>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-7,lower-latin) ". "}.lst-kix_2wxk5sk3ailv-4>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-4,lower-latin) ". "}.lst-kix_2wxk5sk3ailv-8>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-8,lower-roman) ". "}.lst-kix_ivmur5kk55ke-8>li:before{content:"\0025cf   "}.lst-kix_kw8utb3obtvt-3>li:before{content:"\0025cb   "}.lst-kix_kw8utb3obtvt-7>li:before{content:"\0025c6   "}ol.lst-kix_7tb268x5qth-7.start{counter-reset:lst-ctn-kix_7tb268x5qth-7 0}ol.lst-kix_2wxk5sk3ailv-2{list-style-type:none}.lst-kix_n1gqd67us0zz-1>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-1,lower-latin) ". "}.lst-kix_n1gqd67us0zz-3>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-3,decimal) ". "}.lst-kix_k3d9atnt3kqd-0>li:before{content:"\0025cf   "}ol.lst-kix_2wxk5sk3ailv-0{list-style-type:none}ol.lst-kix_2wxk5sk3ailv-5{list-style-type:none}ol.lst-kix_2wxk5sk3ailv-6{list-style-type:none}.lst-kix_dkp7uoq46esk-1>li:before{content:"\0025cb   "}.lst-kix_ivmur5kk55ke-6>li:before{content:"\0025cb   "}.lst-kix_kw8utb3obtvt-5>li:before{content:"\0025cf   "}ol.lst-kix_2wxk5sk3ailv-3{list-style-type:none}ol.lst-kix_2wxk5sk3ailv-4{list-style-type:none}.lst-kix_dkp7uoq46esk-3>li:before{content:"\0025cf   "}ol.lst-kix_2wxk5sk3ailv-7{list-style-type:none}ol.lst-kix_2wxk5sk3ailv-8{list-style-type:none}ul.lst-kix_wl87r0b7y0dk-8{list-style-type:none}ul.lst-kix_wl87r0b7y0dk-7{list-style-type:none}ul.lst-kix_wl87r0b7y0dk-6{list-style-type:none}.lst-kix_b110zvjx6803-6>li{counter-increment:lst-ctn-kix_b110zvjx6803-6}ol.lst-kix_n1gqd67us0zz-1.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-1 0}ul.lst-kix_wl87r0b7y0dk-5{list-style-type:none}.lst-kix_7tb268x5qth-8>li{counter-increment:lst-ctn-kix_7tb268x5qth-8}ul.lst-kix_wl87r0b7y0dk-4{list-style-type:none}ul.lst-kix_wl87r0b7y0dk-3{list-style-type:none}ul.lst-kix_wl87r0b7y0dk-2{list-style-type:none}ol.lst-kix_n1gqd67us0zz-4.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-4 0}ul.lst-kix_wl87r0b7y0dk-1{list-style-type:none}ul.lst-kix_wl87r0b7y0dk-0{list-style-type:none}.lst-kix_n1gqd67us0zz-4>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-4}.lst-kix_p9gl7kquprfc-8>li:before{content:"\0025a0   "}.lst-kix_dkp7uoq46esk-5>li:before{content:"\0025a0   "}.lst-kix_kw8utb3obtvt-1>li:before{content:"\0025c6   "}.lst-kix_7tb268x5qth-7>li:before{content:"(" counter(lst-ctn-kix_7tb268x5qth-7,lower-latin) ") "}.lst-kix_b110zvjx6803-1>li{counter-increment:lst-ctn-kix_b110zvjx6803-1}.lst-kix_2wxk5sk3ailv-0>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-0}ol.lst-kix_7tb268x5qth-6.start{counter-reset:lst-ctn-kix_7tb268x5qth-6 0}.lst-kix_2wxk5sk3ailv-6>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-6}.lst-kix_dkp7uoq46esk-7>li:before{content:"\0025cb   "}.lst-kix_k3d9atnt3kqd-8>li:before{content:"\0025a0   "}.lst-kix_7tb268x5qth-5>li:before{content:"(" counter(lst-ctn-kix_7tb268x5qth-5,lower-latin) ") "}.lst-kix_b110zvjx6803-7>li{counter-increment:lst-ctn-kix_b110zvjx6803-7}.lst-kix_om4jn8q1pf5n-6>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-6}.lst-kix_k3d9atnt3kqd-2>li:before{content:"\0025a0   "}.lst-kix_k3d9atnt3kqd-4>li:before{content:"\0025cb   "}.lst-kix_2wxk5sk3ailv-0>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-0,decimal) ". "}.lst-kix_2wxk5sk3ailv-5>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-5}.lst-kix_2wxk5sk3ailv-2>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-2,lower-roman) ". "}.lst-kix_id87hou1ta7n-7>li:before{content:"\0025c6   "}.lst-kix_k3d9atnt3kqd-6>li:before{content:"\0025cf   "}.lst-kix_om4jn8q1pf5n-0>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-0}ol.lst-kix_2wxk5sk3ailv-2.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-2 0}ul.lst-kix_id87hou1ta7n-5{list-style-type:none}ul.lst-kix_dkp7uoq46esk-1{list-style-type:none}ul.lst-kix_id87hou1ta7n-4{list-style-type:none}.lst-kix_om4jn8q1pf5n-3>li:before{content:"" counter(lst-ctn-kix_om4jn8q1pf5n-3,lower-latin) ") "}ul.lst-kix_dkp7uoq46esk-2{list-style-type:none}.lst-kix_id87hou1ta7n-1>li:before{content:"\0025c6   "}.lst-kix_id87hou1ta7n-3>li:before{content:"\0025cb   "}ul.lst-kix_id87hou1ta7n-7{list-style-type:none}ul.lst-kix_id87hou1ta7n-6{list-style-type:none}ul.lst-kix_dkp7uoq46esk-0{list-style-type:none}ul.lst-kix_id87hou1ta7n-1{list-style-type:none}ul.lst-kix_dkp7uoq46esk-5{list-style-type:none}ul.lst-kix_id87hou1ta7n-0{list-style-type:none}.lst-kix_om4jn8q1pf5n-5>li:before{content:"(" counter(lst-ctn-kix_om4jn8q1pf5n-5,lower-latin) ") "}ul.lst-kix_dkp7uoq46esk-6{list-style-type:none}ul.lst-kix_id87hou1ta7n-3{list-style-type:none}ul.lst-kix_dkp7uoq46esk-3{list-style-type:none}ul.lst-kix_id87hou1ta7n-2{list-style-type:none}ul.lst-kix_dkp7uoq46esk-4{list-style-type:none}.lst-kix_om4jn8q1pf5n-7>li:before{content:"(" counter(lst-ctn-kix_om4jn8q1pf5n-7,lower-latin) ") "}.lst-kix_id87hou1ta7n-5>li:before{content:"\0025cf   "}ul.lst-kix_dkp7uoq46esk-7{list-style-type:none}.lst-kix_7tb268x5qth-7>li{counter-increment:lst-ctn-kix_7tb268x5qth-7}ul.lst-kix_dkp7uoq46esk-8{list-style-type:none}ol.lst-kix_n1gqd67us0zz-2.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-2 0}ul.lst-kix_id87hou1ta7n-8{list-style-type:none}ol.lst-kix_om4jn8q1pf5n-0.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-0 0}.lst-kix_7tb268x5qth-1>li{counter-increment:lst-ctn-kix_7tb268x5qth-1}.lst-kix_7tb268x5qth-3>li:before{content:"" counter(lst-ctn-kix_7tb268x5qth-3,lower-latin) ") "}.lst-kix_7tb268x5qth-1>li:before{content:"" counter(lst-ctn-kix_7tb268x5qth-1,upper-latin) ". "}ol.lst-kix_om4jn8q1pf5n-7{list-style-type:none}ol.lst-kix_om4jn8q1pf5n-6{list-style-type:none}.lst-kix_2wxk5sk3ailv-3>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-3}.lst-kix_om4jn8q1pf5n-4>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-4}ol.lst-kix_om4jn8q1pf5n-8{list-style-type:none}ol.lst-kix_2wxk5sk3ailv-8.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-8 0}.lst-kix_wl87r0b7y0dk-5>li:before{content:"\0025a0   "}.lst-kix_wl87r0b7y0dk-7>li:before{content:"\0025cb   "}ol.lst-kix_om4jn8q1pf5n-3{list-style-type:none}ol.lst-kix_om4jn8q1pf5n-2{list-style-type:none}ol.lst-kix_om4jn8q1pf5n-5{list-style-type:none}ol.lst-kix_om4jn8q1pf5n-4{list-style-type:none}.lst-kix_wl87r0b7y0dk-2>li:before{content:"\0025a0   "}.lst-kix_wl87r0b7y0dk-6>li:before{content:"\0025cf   "}ol.lst-kix_om4jn8q1pf5n-1{list-style-type:none}ol.lst-kix_om4jn8q1pf5n-0{list-style-type:none}.lst-kix_wl87r0b7y0dk-3>li:before{content:"\0025cf   "}ol.lst-kix_om4jn8q1pf5n-4.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-4 0}.lst-kix_wl87r0b7y0dk-4>li:before{content:"\0025cb   "}.lst-kix_wl87r0b7y0dk-1>li:before{content:"\0025cb   "}ol.lst-kix_b110zvjx6803-5.start{counter-reset:lst-ctn-kix_b110zvjx6803-5 0}ol.lst-kix_n1gqd67us0zz-0.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-0 0}.lst-kix_wl87r0b7y0dk-0>li:before{content:"\0025cf   "}ul.lst-kix_k3d9atnt3kqd-8{list-style-type:none}.lst-kix_om4jn8q1pf5n-2>li:before{content:"" counter(lst-ctn-kix_om4jn8q1pf5n-2,decimal) ". "}ol.lst-kix_7tb268x5qth-5.start{counter-reset:lst-ctn-kix_7tb268x5qth-5 0}.lst-kix_om4jn8q1pf5n-0>li:before{content:"" counter(lst-ctn-kix_om4jn8q1pf5n-0,upper-roman) ". "}.lst-kix_om4jn8q1pf5n-1>li:before{content:"" counter(lst-ctn-kix_om4jn8q1pf5n-1,upper-latin) ". "}ul.lst-kix_lhffz7nho2oz-8{list-style-type:none}ul.lst-kix_lhffz7nho2oz-7{list-style-type:none}ul.lst-kix_k3d9atnt3kqd-0{list-style-type:none}ul.lst-kix_lhffz7nho2oz-6{list-style-type:none}ul.lst-kix_k3d9atnt3kqd-1{list-style-type:none}ul.lst-kix_lhffz7nho2oz-5{list-style-type:none}.lst-kix_om4jn8q1pf5n-2>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-2}ul.lst-kix_k3d9atnt3kqd-2{list-style-type:none}ul.lst-kix_lhffz7nho2oz-4{list-style-type:none}ul.lst-kix_k3d9atnt3kqd-3{list-style-type:none}ul.lst-kix_lhffz7nho2oz-3{list-style-type:none}ul.lst-kix_k3d9atnt3kqd-4{list-style-type:none}ul.lst-kix_lhffz7nho2oz-2{list-style-type:none}ul.lst-kix_k3d9atnt3kqd-5{list-style-type:none}ul.lst-kix_lhffz7nho2oz-1{list-style-type:none}ul.lst-kix_k3d9atnt3kqd-6{list-style-type:none}ul.lst-kix_lhffz7nho2oz-0{list-style-type:none}ul.lst-kix_k3d9atnt3kqd-7{list-style-type:none}.lst-kix_6ueprapoytcd-1>li:before{content:"\0025cb   "}.lst-kix_6ueprapoytcd-0>li:before{content:"\0025cf   "}.lst-kix_6ueprapoytcd-4>li:before{content:"\0025cb   "}.lst-kix_6ueprapoytcd-3>li:before{content:"\0025cf   "}.lst-kix_6ueprapoytcd-2>li:before{content:"\0025a0   "}.lst-kix_6ueprapoytcd-8>li:before{content:"\0025a0   "}.lst-kix_7tb268x5qth-3>li{counter-increment:lst-ctn-kix_7tb268x5qth-3}.lst-kix_6ueprapoytcd-7>li:before{content:"\0025cb   "}ol.lst-kix_2wxk5sk3ailv-3.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-3 0}.lst-kix_6ueprapoytcd-5>li:before{content:"\0025a0   "}.lst-kix_6ueprapoytcd-6>li:before{content:"\0025cf   "}.lst-kix_n1gqd67us0zz-0>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-0,decimal) ". "}ol.lst-kix_b110zvjx6803-0.start{counter-reset:lst-ctn-kix_b110zvjx6803-0 0}.lst-kix_b110zvjx6803-8>li{counter-increment:lst-ctn-kix_b110zvjx6803-8}ol.lst-kix_n1gqd67us0zz-5.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-5 0}.lst-kix_pny75y3i6z9w-1>li:before{content:"\0025cb   "}.lst-kix_pny75y3i6z9w-2>li:before{content:"\0025a0   "}.lst-kix_pny75y3i6z9w-3>li:before{content:"\0025cf   "}.lst-kix_n1gqd67us0zz-0>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-0}.lst-kix_pny75y3i6z9w-0>li:before{content:"\0025cf   "}.lst-kix_pny75y3i6z9w-8>li:before{content:"\0025a0   "}ol.lst-kix_n1gqd67us0zz-6.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-6 0}.lst-kix_pny75y3i6z9w-7>li:before{content:"\0025cb   "}ol.lst-kix_om4jn8q1pf5n-3.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-3 0}.lst-kix_2wxk5sk3ailv-7>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-7}.lst-kix_pny75y3i6z9w-5>li:before{content:"\0025a0   "}.lst-kix_pny75y3i6z9w-6>li:before{content:"\0025cf   "}.lst-kix_pny75y3i6z9w-4>li:before{content:"\0025cb   "}.lst-kix_p9gl7kquprfc-7>li:before{content:"\0025cb   "}.lst-kix_b110zvjx6803-4>li{counter-increment:lst-ctn-kix_b110zvjx6803-4}.lst-kix_b110zvjx6803-5>li:before{content:"(" counter(lst-ctn-kix_b110zvjx6803-5,lower-latin) ") "}.lst-kix_b110zvjx6803-7>li:before{content:"(" counter(lst-ctn-kix_b110zvjx6803-7,lower-latin) ") "}.lst-kix_p9gl7kquprfc-3>li:before{content:"\0025cf   "}.lst-kix_b110zvjx6803-1>li:before{content:"" counter(lst-ctn-kix_b110zvjx6803-1,upper-latin) ". "}ol.lst-kix_om4jn8q1pf5n-8.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-8 0}.lst-kix_p9gl7kquprfc-5>li:before{content:"\0025a0   "}ol.lst-kix_7tb268x5qth-0{list-style-type:none}ol.lst-kix_7tb268x5qth-1{list-style-type:none}ol.lst-kix_7tb268x5qth-8{list-style-type:none}.lst-kix_b110zvjx6803-5>li{counter-increment:lst-ctn-kix_b110zvjx6803-5}ol.lst-kix_7tb268x5qth-6{list-style-type:none}ol.lst-kix_7tb268x5qth-7{list-style-type:none}.lst-kix_b110zvjx6803-3>li:before{content:"" counter(lst-ctn-kix_b110zvjx6803-3,lower-latin) ") "}ol.lst-kix_7tb268x5qth-4{list-style-type:none}ol.lst-kix_7tb268x5qth-5{list-style-type:none}.lst-kix_p9gl7kquprfc-1>li:before{content:"\0025cb   "}ol.lst-kix_7tb268x5qth-2{list-style-type:none}ol.lst-kix_7tb268x5qth-3{list-style-type:none}.lst-kix_ivmur5kk55ke-7>li:before{content:"\0025c6   "}.lst-kix_kw8utb3obtvt-6>li:before{content:"\0025cb   "}.lst-kix_n1gqd67us0zz-6>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-6,decimal) ". "}ul.lst-kix_pny75y3i6z9w-7{list-style-type:none}ul.lst-kix_6ueprapoytcd-1{list-style-type:none}.lst-kix_2wxk5sk3ailv-5>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-5,lower-roman) ". "}ul.lst-kix_pny75y3i6z9w-8{list-style-type:none}ul.lst-kix_6ueprapoytcd-2{list-style-type:none}ul.lst-kix_pny75y3i6z9w-5{list-style-type:none}ul.lst-kix_6ueprapoytcd-3{list-style-type:none}ul.lst-kix_pny75y3i6z9w-6{list-style-type:none}ul.lst-kix_6ueprapoytcd-4{list-style-type:none}.lst-kix_kw8utb3obtvt-4>li:before{content:"\0025c6   "}.lst-kix_kw8utb3obtvt-8>li:before{content:"\0025cf   "}.lst-kix_n1gqd67us0zz-4>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-4,lower-latin) ". "}.lst-kix_n1gqd67us0zz-8>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-8,lower-roman) ". "}ul.lst-kix_pny75y3i6z9w-3{list-style-type:none}.lst-kix_ivmur5kk55ke-5>li:before{content:"\0025cf   "}ul.lst-kix_pny75y3i6z9w-4{list-style-type:none}ul.lst-kix_pny75y3i6z9w-1{list-style-type:none}ul.lst-kix_pny75y3i6z9w-2{list-style-type:none}ul.lst-kix_6ueprapoytcd-0{list-style-type:none}.lst-kix_n1gqd67us0zz-2>li:before{content:"" counter(lst-ctn-kix_n1gqd67us0zz-2,lower-roman) ". "}ol.lst-kix_om4jn8q1pf5n-5.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-5 0}ol.lst-kix_b110zvjx6803-6.start{counter-reset:lst-ctn-kix_b110zvjx6803-6 0}ul.lst-kix_pny75y3i6z9w-0{list-style-type:none}.lst-kix_dkp7uoq46esk-0>li:before{content:"\0025cf   "}ol.lst-kix_n1gqd67us0zz-7.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-7 0}.lst-kix_7tb268x5qth-5>li{counter-increment:lst-ctn-kix_7tb268x5qth-5}ul.lst-kix_6ueprapoytcd-5{list-style-type:none}.lst-kix_k3d9atnt3kqd-1>li:before{content:"\0025cb   "}.lst-kix_2wxk5sk3ailv-7>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-7,lower-latin) ". "}ul.lst-kix_6ueprapoytcd-6{list-style-type:none}.lst-kix_2wxk5sk3ailv-8>li{counter-increment:lst-ctn-kix_2wxk5sk3ailv-8}ul.lst-kix_6ueprapoytcd-7{list-style-type:none}ul.lst-kix_6ueprapoytcd-8{list-style-type:none}.lst-kix_dkp7uoq46esk-4>li:before{content:"\0025cb   "}ul.lst-kix_p9gl7kquprfc-8{list-style-type:none}.lst-kix_kw8utb3obtvt-0>li:before{content:"\002794   "}ul.lst-kix_p9gl7kquprfc-6{list-style-type:none}ul.lst-kix_p9gl7kquprfc-7{list-style-type:none}.lst-kix_dkp7uoq46esk-2>li:before{content:"\0025a0   "}.lst-kix_dkp7uoq46esk-6>li:before{content:"\0025cf   "}ul.lst-kix_p9gl7kquprfc-4{list-style-type:none}ul.lst-kix_p9gl7kquprfc-5{list-style-type:none}.lst-kix_kw8utb3obtvt-2>li:before{content:"\0025cf   "}ul.lst-kix_p9gl7kquprfc-2{list-style-type:none}.lst-kix_om4jn8q1pf5n-8>li{counter-increment:lst-ctn-kix_om4jn8q1pf5n-8}ul.lst-kix_p9gl7kquprfc-3{list-style-type:none}ol.lst-kix_2wxk5sk3ailv-6.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-6 0}ul.lst-kix_p9gl7kquprfc-0{list-style-type:none}ul.lst-kix_p9gl7kquprfc-1{list-style-type:none}.lst-kix_n1gqd67us0zz-7>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-7}.lst-kix_b110zvjx6803-3>li{counter-increment:lst-ctn-kix_b110zvjx6803-3}ol.lst-kix_7tb268x5qth-1.start{counter-reset:lst-ctn-kix_7tb268x5qth-1 0}.lst-kix_n1gqd67us0zz-2>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-2}ol.lst-kix_n1gqd67us0zz-8.start{counter-reset:lst-ctn-kix_n1gqd67us0zz-8 0}.lst-kix_7tb268x5qth-4>li:before{content:"(" counter(lst-ctn-kix_7tb268x5qth-4,decimal) ") "}.lst-kix_7tb268x5qth-8>li:before{content:"(" counter(lst-ctn-kix_7tb268x5qth-8,lower-roman) ") "}ol.lst-kix_b110zvjx6803-3.start{counter-reset:lst-ctn-kix_b110zvjx6803-3 0}.lst-kix_k3d9atnt3kqd-7>li:before{content:"\0025cb   "}.lst-kix_dkp7uoq46esk-8>li:before{content:"\0025a0   "}.lst-kix_7tb268x5qth-6>li:before{content:"(" counter(lst-ctn-kix_7tb268x5qth-6,lower-roman) ") "}.lst-kix_n1gqd67us0zz-8>li{counter-increment:lst-ctn-kix_n1gqd67us0zz-8}.lst-kix_k3d9atnt3kqd-3>li:before{content:"\0025cf   "}ul.lst-kix_ivmur5kk55ke-8{list-style-type:none}ul.lst-kix_ivmur5kk55ke-7{list-style-type:none}.lst-kix_2wxk5sk3ailv-1>li:before{content:"\0025cb   "}ul.lst-kix_ivmur5kk55ke-2{list-style-type:none}ul.lst-kix_ivmur5kk55ke-1{list-style-type:none}ul.lst-kix_ivmur5kk55ke-0{list-style-type:none}ol.lst-kix_2wxk5sk3ailv-7.start{counter-reset:lst-ctn-kix_2wxk5sk3ailv-7 0}ul.lst-kix_ivmur5kk55ke-6{list-style-type:none}.lst-kix_id87hou1ta7n-8>li:before{content:"\0025cf   "}.lst-kix_k3d9atnt3kqd-5>li:before{content:"\0025a0   "}ul.lst-kix_ivmur5kk55ke-5{list-style-type:none}.lst-kix_2wxk5sk3ailv-3>li:before{content:"" counter(lst-ctn-kix_2wxk5sk3ailv-3,decimal) ". "}ul.lst-kix_ivmur5kk55ke-4{list-style-type:none}ul.lst-kix_ivmur5kk55ke-3{list-style-type:none}.lst-kix_id87hou1ta7n-2>li:before{content:"\0025cf   "}ol.lst-kix_b110zvjx6803-4.start{counter-reset:lst-ctn-kix_b110zvjx6803-4 0}ol.lst-kix_7tb268x5qth-0.start{counter-reset:lst-ctn-kix_7tb268x5qth-0 0}.lst-kix_om4jn8q1pf5n-4>li:before{content:"(" counter(lst-ctn-kix_om4jn8q1pf5n-4,decimal) ") "}.lst-kix_id87hou1ta7n-6>li:before{content:"\0025cb   "}.lst-kix_om4jn8q1pf5n-6>li:before{content:"(" counter(lst-ctn-kix_om4jn8q1pf5n-6,lower-roman) ") "}.lst-kix_id87hou1ta7n-4>li:before{content:"\0025c6   "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_dbv9dzfh4djb-5{list-style-type:none}ul.lst-kix_dbv9dzfh4djb-4{list-style-type:none}ul.lst-kix_dbv9dzfh4djb-7{list-style-type:none}ul.lst-kix_dbv9dzfh4djb-6{list-style-type:none}ul.lst-kix_dbv9dzfh4djb-1{list-style-type:none}.lst-kix_om4jn8q1pf5n-8>li:before{content:"(" counter(lst-ctn-kix_om4jn8q1pf5n-8,lower-roman) ") "}ul.lst-kix_dbv9dzfh4djb-0{list-style-type:none}.lst-kix_7tb268x5qth-0>li:before{content:"" counter(lst-ctn-kix_7tb268x5qth-0,upper-roman) ". "}ul.lst-kix_dbv9dzfh4djb-3{list-style-type:none}.lst-kix_7tb268x5qth-4>li{counter-increment:lst-ctn-kix_7tb268x5qth-4}ul.lst-kix_dbv9dzfh4djb-2{list-style-type:none}.lst-kix_id87hou1ta7n-0>li:before{content:"\002794   "}ol.lst-kix_om4jn8q1pf5n-6.start{counter-reset:lst-ctn-kix_om4jn8q1pf5n-6 0}ul.lst-kix_dbv9dzfh4djb-8{list-style-type:none}.lst-kix_7tb268x5qth-2>li:before{content:"" counter(lst-ctn-kix_7tb268x5qth-2,decimal) ". "}.lst-kix_wl87r0b7y0dk-8>li:before{content:"\0025a0   "}ol{margin:0;padding:0}table td,table th{padding:0}.c7{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:48pt;border-top-color:#000000;border-bottom-style:solid}.c25{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:157.5pt;border-top-color:#000000;border-bottom-style:solid}.c46{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:111pt;border-top-color:#000000;border-bottom-style:solid}.c36{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:53.2pt;border-top-color:#000000;border-bottom-style:solid}.c11{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:156pt;border-top-color:#000000;border-bottom-style:solid}.c13{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:30pt;border-top-color:#000000;border-bottom-style:solid}.c10{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#000000;border-bottom-style:solid}.c31{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:166.5pt;border-top-color:#000000;border-bottom-style:solid}.c39{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:141.8pt;border-top-color:#000000;border-bottom-style:solid}.c38{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:138.8pt;border-top-color:#000000;border-bottom-style:solid}.c21{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:86.2pt;border-top-color:#000000;border-bottom-style:solid}.c22{margin-left:-63pt;padding-top:18pt;padding-bottom:6pt;line-height:2.0;orphans:2;widows:2;text-align:center;margin-right:-58.5pt}.c32{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c0{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Times New Roman";font-style:normal}.c24{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c44{margin-left:-67.5pt;padding-top:0pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:center}.c16{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Times New Roman";font-style:normal}.c23{padding-top:0pt;text-indent:36pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c9{padding-top:18pt;text-indent:36pt;padding-bottom:6pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Times New Roman";font-style:normal}.c55{padding-top:18pt;padding-bottom:10pt;line-height:2.0;orphans:2;widows:2;text-align:center}.c19{padding-top:18pt;padding-bottom:6pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c12{padding-top:18pt;padding-bottom:6pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c45{padding-top:0pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:center}.c40{padding-top:0pt;padding-bottom:0pt;line-height:2.0;orphans:2;widows:2;text-align:left}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c27{padding-top:18pt;padding-bottom:6pt;line-height:2.0;orphans:2;widows:2;text-align:center}.c17{color:#000000;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:italic}.c15{color:#000000;text-decoration:none;vertical-align:baseline;font-size:20pt;font-style:normal}.c29{border-spacing:0;border-collapse:collapse;margin-right:auto}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c33{font-weight:700;font-size:16pt;font-family:"Times New Roman";font-style:normal}.c28{color:#000000;text-decoration:none;vertical-align:baseline}.c41{font-size:14pt;font-weight:700;font-family:"Times New Roman"}.c53{margin-left:-54pt;margin-right:-58.5pt}.c14{font-weight:400;font-family:"Times New Roman"}.c47{font-size:17pt;font-style:normal}.c20{font-size:8pt;font-style:italic}.c52{color:#333333;font-size:10.5pt}.c26{max-width:468pt;padding:72pt 72pt 72pt 72pt}.c5{padding:0;margin:0}.c30{font-size:18pt;font-style:normal}.c51{margin-left:-36pt;text-indent:-36pt}.c35{font-size:12pt;font-style:normal}.c54{margin-left:-67.5pt;text-indent:31.5pt}.c49{margin-left:-58.5pt}.c42{font-style:italic}.c48{text-indent:-67.5pt}.c3{height:0pt}.c50{margin-right:-36pt}.c34{font-size:10pt}.c43{margin-left:-63pt}.c37{margin-left:36pt}.c8{height:11pt}.c18{background-color:#ffffff}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c18 c26 doc-content"><p class="c45 c8"><span class="c1"></span></p><p class="c45"><span class="c28 c14 c47">STA 141A Final Project</span></p><p class="c45"><span class="c28 c14 c47">By: Soha Ahmed</span></p><p class="c12 c8"><span class="c28 c14 c30"></span></p><p class="c55"><span class="c14 c15">Instructor: Shizhe Chen</span></p><p class="c27 c8"><span class="c2"></span></p><p class="c27 c8"><span class="c2"></span></p><p class="c27 c8"><span class="c2"></span></p><p class="c27 c8"><span class="c2"></span></p><p class="c27 c8"><span class="c2"></span></p><p class="c12 c8"><span class="c2"></span></p><p class="c12 c8"><span class="c2"></span></p><p class="c8 c27"><span class="c2"></span></p><p class="c45"><span class="c28 c33">Topic: Predicting Decision Outcomes in Mice</span></p><p class="c40 c8"><span class="c1"></span></p><ol class="c5 lst-kix_b110zvjx6803-0 start" start="1"><li class="c32 li-bullet-0"><span class="c0">Abstract</span></li></ol><p class="c23 c37"><span class="c1">In this project, we aim to build a predictive model that will be helpful for classification of trial outcomes (success or failure). This predictive model will be based on neural activity data from visual discrimination tasks performed by mice. The dataset consists of spike train recordings from neurons in the visual cortex along with trial stimuli conditions (left and right contrast levels). The study is structured into three parts: exploratory data analysis (EDA), data integration, and model development. We will test this on various machine learning models to determine which is the most efficient predictor of them all.</span></p><p class="c40 c8"><span class="c28 c14 c35"></span></p><ol class="c5 lst-kix_b110zvjx6803-0" start="2"><li class="c32 li-bullet-0"><span class="c16">Introduction</span></li></ol><p class="c40 c37"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In recent years, there has been a significant interaction between biological sciences and data science, which has provided an exciting opportunity to analyze complex biological data and gather meaningful insights from it. In this project, we leverage data collected from the neural activity of mice to build a predictive algorithm that speculates the outcome of behavioral trials. </span></p><p class="c40 c37"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The dataset consists of neural activity recordings taken from the visual cortex of the mice during a decision-making task. In each trial, mice were presented with a visual stimulus of varying contrasts and were required to make decisions. Those were determined by the way the wheel, placed in front of them, was turned. The outcome of these decisions were either success or failure. Along with the behavioral outcomes, the dataset also includes neural spike trains. They represent firing patterns of neurons in response to the stimuli.</span></p><p class="c40 c37"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In this project, we aim to develop a predictive algorithm that can classify the outcome of stimulus trials based off of the data we have on neural activity. The key steps involved: Exploratory data analysis, Data integration, and Predictive modeling</span></p><ol class="c5 lst-kix_b110zvjx6803-0" start="3"><li class="c32 li-bullet-0"><span class="c41">Data Processing</span></li></ol><p class="c23"><span class="c1">With such complicated datasets in hand, we will need to examine them before taking any steps towards building the prediction algorithm. We load the 18 session files into a list. For each session, it extracts data vital for our analysis, such as mouse_name, date_exp, and neural data like spike trains (spks). It includes the number of neurons, trials, and unique brain areas. It also calculates the success rate based on each feedback type. </span></p><p class="c40"><img src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image1.png"></p><ul class="c5 lst-kix_k3d9atnt3kqd-0 start"><li class="c32 li-bullet-0"><span class="c1">Number of successful trials: the count of trials where feedback is 1.</span></li><li class="c32 li-bullet-0"><span class="c1">Total number of trials: The total number of trials in the session.</span></li></ul><p class="c23"><span class="c1">All of these metrics are stored in a list of dictionaries, which is then converted into a dataframe for ease of analysis in the future. This dataframe is essential as it summarizes each session&rsquo;s characteristics, which can be used further for exploratory data analysis.</span></p><p class="c40"><span class="c1">Session data info:</span></p><table class="c29"><tr class="c3"><td class="c13" colspan="1" rowspan="1"><p class="c6"><span class="c1">#</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c6"><span class="c1">Column</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c6"><span class="c1">Non-null count</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c6"><span class="c1">Data type</span></p></td></tr><tr class="c3"><td class="c13" colspan="1" rowspan="1"><p class="c6"><span class="c1">0</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c6"><span class="c1">mouse_name </span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c6"><span class="c1">18 non-null</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c6"><span class="c1">object</span></p></td></tr><tr class="c3"><td class="c13" colspan="1" rowspan="1"><p class="c6"><span class="c1">1</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c6"><span class="c1">date_exp </span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c6"><span class="c1">18 non-null</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c6"><span class="c1">object</span></p></td></tr><tr class="c3"><td class="c13" colspan="1" rowspan="1"><p class="c6"><span class="c1">2</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c6"><span class="c1">n_brain_data </span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c6"><span class="c1">18 non-null</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c6"><span class="c1">int64</span></p></td></tr><tr class="c3"><td class="c13" colspan="1" rowspan="1"><p class="c6"><span class="c1">3</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c6"><span class="c1">n_neurons</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c6"><span class="c1">18 non-null</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c6"><span class="c1">int64</span></p></td></tr><tr class="c3"><td class="c13" colspan="1" rowspan="1"><p class="c6"><span class="c1">4</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c6"><span class="c1">n_trials</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c6"><span class="c1">18 non-null</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c6"><span class="c1">int64</span></p></td></tr><tr class="c3"><td class="c13" colspan="1" rowspan="1"><p class="c6"><span class="c1">5</span></p></td><td class="c39" colspan="1" rowspan="1"><p class="c6"><span class="c1">success_rate</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c6"><span class="c1">18 non-null</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c6"><span class="c1">float</span></p></td></tr></table><p class="c40"><span class="c28 c14 c20">table 1: summarizing the session data info</span></p><p class="c40 c8"><span class="c28 c14 c20"></span></p><ol class="c5 lst-kix_b110zvjx6803-0" start="4"><li class="c32 li-bullet-0"><span class="c0">Exploratory Data Analysis</span></li></ol><p class="c23"><span class="c14">Since there are multiple parameters for this analysis, I have broken down the entire EDA process into multiple sub sections. </span></p><p class="c40"><span class="c14 c17">Contrast analysis</span></p><p class="c12 c43"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 794.09px; height: 341.31px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image19.png" style="width: 794.09px; height: 341.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">Figure 1</span></p><p class="c23"><span class="c1">The histogram in figure 1 shows 2 histograms that depict the distribution of contrast values for left and right visual stimuli. Both the plots display the probability of different contrast levels. The important experimental implications suggest that there&rsquo;s a roughly equal distribution between no stimulus (0) and high stimulus (1) on both sides. The middle contrasts (0.25 and 0.5) were used less frequently. The distributions are smaller between left and right. This suggests a balanced experimental design. It makes sense to have multiple 0 contrast trials. It is because these are hold-still trials where mice are not expected to turn the wheel. Both the left and right contrast distributions share a similar pattern. This suggests a symmetrical experimental condition where contrasts were predominantly set to either no contrast or full contrast. </span></p><p class="c40 c8"><span class="c1"></span></p><p class="c44"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 780.50px; height: 594.99px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image9.png" style="width: 780.50px; height: 594.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">Figure 2</span></p><p class="c23"><span class="c1">Figure 2 above displays the frequency of trials with equal vs. non-equal contrast values. We can see that non-equal contrasts dominate. Non-equal contracts are essentially used more, as this experiment was used to analyze decision-making capabilities since they create a clear choice based on contrast differences. </span></p><p class="c40"><span class="c14">Now, check out the success rates. For the record: </span><img src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image2.png"></p><p class="c40 c8"><span class="c1"></span></p><p class="c40"><span class="c17 c14">Success rate analysis</span></p><p class="c40 c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 777.18px; height: 387.50px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image13.png" style="width: 777.18px; height: 387.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 3</span></p><p class="c23"><span class="c1">From figure 3, we could see that the success rate generally had an upward trend. It indicates that the mice may be improving their performance pertaining to the particular task over time. We could see some sessions with a noticeable drop in the success rates. This could have multiple reasons, like maybe changes in the experimental conditions or the conditions of the mouse during the session. Towards the later end of the stage, the success rate is the highest, which suggests a learning effect because of the repetition of the task. </span></p><p class="c45 c43"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 772.50px; height: 553.99px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image7.png" style="width: 772.50px; height: 553.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">Figure 4</span></p><p class="c9"><span class="c28 c14 c35">The session-to-session variation in success rates (Figure 4) shows a bimodal distribution with modes at 0.65 and 0.8. This suggests two distinct trends of performance, perhaps as a function of differences in the performance of individual mice or in session conditions. These findings are consistent with the variation in success rates between mice (e.g., Lederberg vs. Cori) and sessions.</span></p><p class="c12 c54"><span class="c14">Doing statistical analysis: two-way ANOVA test to check how success rate is influenced by mouse identity, contrast difference, and their interaction. However, before performing the F test, let&#39;s check if the data meets the requirements for the test. Let&rsquo;s check the interaction plot of the factors involved in this test.</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 799.50px; height: 530.01px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image21.png" style="width: 799.50px; height: 530.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 5</span></p><p class="c9"><span class="c14">Figure 5 shows a fascinating relationship between the two factors: contrast difference and the mean success rate. The x axis represents contrast difference, with 0 being the lowest and 1 being the highest. All mice generally show better performance with the increase in the contrast differences. This makes intuitive sense, as when there is a greater difference in the visual stimuli, the easier it is to distinguish for the mice. This visualization is a vital preliminary check for potential interaction effects between contrast difference and mouse identity on success rates. The non-parallel lines provide a visual proof of potential interaction between the two factors.</span></p><p class="c12"><span class="c1">Below is a table showing the results obtained after performing the F test</span></p><table class="c29"><tr class="c3"><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c24">Source</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c6"><span class="c24">Sum of Squares (SS)</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c6"><span class="c24">df</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c24">F value</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c24">P value</span></p></td></tr><tr class="c3"><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c1">Mouse Name</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c6"><span class="c1">10.45</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c6"><span class="c1">3</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c1">17.80</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><img src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image3.png"></p></td></tr><tr class="c3"><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c1">Contrast Difference</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c6"><span class="c1">24.98</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c6"><span class="c1">4</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c1">31.92</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><img src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image4.png"></p></td></tr><tr class="c3"><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c1">Mouse Name x Contrast Difference (Interaction)</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c6"><span class="c1">21.23</span></p><p class="c6 c8"><span class="c1"></span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c6"><span class="c1">12</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c1">9.04</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><img src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image5.png"></p></td></tr><tr class="c3"><td class="c31" colspan="1" rowspan="1"><p class="c6"><span class="c1">Residual (Error)</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c6"><span class="c1">990.03</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c6"><span class="c1">5061</span></p></td><td class="c36" colspan="1" rowspan="1"><p class="c6"><span class="c1">-</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c6"><span class="c1">-</span></p></td></tr></table><p class="c12"><span class="c28 c14 c20">table 2: ANOVA table describing the values regarding the statistical test to check if there is a relationship between contrast difference and mouse success rate.</span></p><p class="c9"><span class="c14">From the test, we can see that different mice have statistically different success rates. We can conclude that some mice have learned the task and might have better cognitive abilities. Moving onto the next thing, the contrast difference is highly significant. The higher the contrast difference, the higher the success rates, which confirms that decision-making difficulty depends on high contrast differences. Moving onto the interaction effect, the effect of contrast difference is not the same across all mice. Some mice might struggle more than others when it comes to low contrasts. This suggests that there is variability in how contrast impacts decision-making.</span></p><p class="c12"><span class="c17 c14">Behavioral analysis</span></p><table class="c29"><tr class="c3"><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c24">Mouse Name</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c24">Success Rate</span></p></td></tr><tr class="c3"><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Cori</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c34 c18">0.633670</span></p></td></tr><tr class="c3"><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Forssmann</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c34 c18">0.685025</span></p></td></tr><tr class="c3"><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Hench</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18 c34">0.686123</span></p></td></tr><tr class="c3"><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Lederberg</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c14 c34 c18">0.763936</span></p></td></tr></table><p class="c12"><span class="c28 c14 c20">table 3: mouse name with their corresponding success rate</span></p><p class="c9"><span class="c14">The table shows the average success rate for each mouse across all recorded sessions. Lederberg performed the best out of the 4 of them, which depicts that there is strong decision-making accuracy compared to the other mice involved in the experiment. Cori had the lowest success rate. It struggled to compare to others. This sheds light on the learning ability differences within the mice.</span></p><table class="c29"><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c24">Mouse Name</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c24">Total Improvement</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c24">Average Improvement per session</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Cori</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.057</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.19</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Forssmann</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.004</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.001</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Hench</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.151</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.038</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c14 c18">Lederberg</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.067</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">0.01</span></p></td></tr></table><p class="c12 c43"><span class="c14 c20">table 4: the mouse improvement/learning curve of every mice</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 795.61px; height: 401.86px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image12.png" style="width: 795.61px; height: 401.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 5</span></p><p class="c9"><span class="c14">Hench showed the most improvement out of all the mice, with a total increase of 15.1%. It also had the highest average improvement per session (3.8%). Lederberg had the most variable performance. There were notable peaks around sessions 2 and 5. Cori showed a steady improvement. There was a 5.7% total increase. Lastly, Forssoman showed the least improvement but maintained a relatively consistent performance. The black dashed line, indicating the rolling average, shows a general upward trend across all sessions. The final sessions show the highest overall performance, suggesting continued learning. All mice showed positive total improvement. This indicates successful learning. Performance variability was higher only in the early sessions.</span></p><p class="c12 c43"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 788.50px; height: 591.66px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image18.png" style="width: 788.50px; height: 591.66px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c28 c14 c20">figure 6 </span></p><p class="c9"><span class="c1">The heatmap in figure 6 visualizes the success rate. The left contrast is on the y-axis, and the right contrast is on the x-axis. The value inside each cell represents the mean success rate for the corresponding contrast conditions. When one side has high contrast and the other side has low contrast, the success rate is generally higher. This suggests that the larger the contrast differences, the easier the decision-making task. When both contrasts are equal, the success rate is moderate. This indicates that when the contrast is equal on both sides, the task might seem more ambiguous. When the contrasts are low, the mice might struggle to distinguish between the options. The redder regions indicate easier conditions; on the contrary, the blue regions depict challenging decision-making circumstances. </span></p><p class="c12"><span class="c17 c14">Neural activity analysis</span></p><p class="c12"><span class="c1">For context, firing rate refers to the mean spike rate of neurons during each trial in a session.</span></p><p class="c22"><img src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image6.png"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 797.27px; height: 400.63px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image23.png" style="width: 797.27px; height: 400.63px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c12"><span class="c14 c20 c28">Figure 7</span></p><p class="c9"><span class="c1">The histogram in figure 7 represents the distribution of neuronal firing rates across various sessions. It allows a clear visualization of a wide range of firing rates. The distribution is highly skewed towards the lower end of the firing rates. This suggests that most neurons are inactive relatively. Only a small subset of them exhibits higher firing rates. The strong skew in the graph suggests that most neurons contribute minimally. Only a few are actively involved in the task of execution. </span></p><p class="c12 c48"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 802.63px; height: 401.32px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image20.png" style="width: 802.63px; height: 401.32px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 8</span></p><p class="c9"><span class="c1">Figure 8 is a line plot that compares average neuronal firing over time for successful and failed trials. The green line represents the trials, with success as the outcome. The red line, on the other hand, corresponds to failure. In the start, both conditions have similar firing rates, but with the progression of time, there is a significant increase in the firing rates. During the 10th time bin, a divergence occurs. This suggests that neural activity plays a role in determining success. This indicates that stronger neuronal engagement is associated with successful trial outcomes. We can see that there is a consistent gap between the two lines. This is an indication of neuronal firing that may help in the prediction of trial success. To conclude, high neuronal activity is a key factor in successful trials.</span></p><p class="c12 c51"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 807.50px; height: 634.31px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image15.png" style="width: 807.50px; height: 634.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c12"><span class="c28 c14 c20">Figure 9</span></p><p class="c9"><span class="c1">Figure 9 is a grid of scatterplots. In here, each subplot represents a different session. The x axis represents the number of trials within each session. On the other hand, the y axis represents the average firing rate of neurons in that trial. Let&rsquo;s move onto discussing some of the general trends across sessions. Some sessions, such as sessions 2, 10, 12, and 17, show consistent firing rates. This could indicate consistency in the neural responses. This tells us that the mouse was engaged throughout the session. Decreasing trends and/or fluction are seen in sessions 1, 6, 11, and 15. Here, the gradual decline might suggest fatigue or disengagement. This might also be due to the positive learning curve that was noticed previously. This might cause fewer neurons to be used over time to complete the task at hand. &nbsp;A few sessions, such as 7, 9, and 11, have high variability in general. Suggests variability in attention of the mouse. This could be due to its lack of motivation or other external factors affecting the neural activity. There could be a possibility of learning effects; fatigue or a shift in the behavior of the mouse could cause such variability. Lastly, some sessions have low firing rates overall, as seen in 4, 5, 16, and 18. There is a high possibility that the neurons were not highly active during these sessions. This could be either due to the learning curve or low contrast difference. </span></p><p class="c12 c8"><span class="c1"></span></p><p class="c12"><span class="c17 c14">Brain Area Analysis</span></p><p class="c12 c43 c50"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 789.50px; height: 562.05px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image22.png" style="width: 789.50px; height: 562.05px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c12"><span class="c28 c14 c20">figure 10</span></p><p class="c9"><span class="c14">The bar plot in figure 10 shows the distribution of neurons across different brain areas in the given dataset. The x axis represents the number of neurons recorded in each brain area in the given dataset. The y axis lists the different brain regions where the neurons were recorded. Each label represents a specific area of the brain of mice. The category &ldquo;root&rdquo; has the highest neuron count. The other areas are TH, CA1, and VISp. potential issues here: when checking the brain area abbreviations in the key reference (</span><span class="c14 c42">Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266&ndash;273 (2019)</span><span class="c1">), the brain area &ldquo;root&rdquo; was not mentioned. </span></p><p class="c12 c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 766.50px; height: 442.21px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image10.png" style="width: 766.50px; height: 442.21px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c14 c20">figure 11</span></p><p class="c9"><span class="c1">The box plot in figure 11 does a analysis of the mean firing rates of the neurons across different regions in the brain, most of the brain areas have a low mean firing rate. The medians are also in the bottom of the box plot. Areas like SC, MRN, ZI and UI have a larger interquartile range and more outliers. Many brain areas have outliers. The firing rate is significantly higher than the others. A question in hand in relation to the outliers. Are these neurons specialized ones for the particular task at hand? Do they play a unique role in processing the simuli? Possibile biological implication from this bar: regions with high mean firing rates might be used for information processing or gathering. The low-activity areas might be used for decision-making. </span></p><p class="c12 c53"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 766.50px; height: 437.30px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image16.png" style="width: 766.50px; height: 437.30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 12</span></p><p class="c9"><span class="c1">In figure 12, each box represents the distribution of success rates across different brain areas. The success rate across the various brain areas ranges from 0.6 to 0.8. Some of the regions, which have a narrow range, imply them having a consistent performance. Regions such as SSCs, LH, ZI, MET show higher median success rates. These areas might be relevant for the behavior being measured in the mice. The brain areas with lower median success rates might not be relevant for the task at hand. </span></p><p class="c12"><span class="c17 c14">Correlation Analysis</span></p><p class="c12"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 712.22px; height: 529.31px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image17.png" style="width: 712.22px; height: 529.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 13</span></p><p class="c9"><span class="c1">The histogram in figure 13 shows the distribution of the correlation coefficient between neuron firing rates and trial outcomes, which are either successful or failures. We can see that the values are centered around 0. This means that most neurons have weak or no correlation with the trial outcome. </span></p><p class="c12"><span class="c17 c14">PCA Analysis</span></p><p class="c9"><span class="c1">We prepared a new dataframe for the neural activity data for dimensionality reduction. This was done by extracting features from each session and trial. For each neuron in each trial, we calculated the mean firing rate across time bins, resulting in a feature vector per trial that represented the average activity of all recorded neurons. Then, we standardized the data and prepared it for PCA analysis.</span></p><p class="c9"><span class="c1">We applied Principal Component Analysis (PCA). this was done to reduce the high-dimensional neural activity data to a lower-dimensional representation. This was done for visualization and analysis.</span></p><p class="c12"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 679.29px; height: 541.04px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image24.png" style="width: 679.29px; height: 541.04px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 14</span></p><p class="c9"><span class="c1">Figure 14 here represents the PCA results with data points color-coded by session ID. session 14 forms a distinct cluster. It seems to have been separated from the other sessions, which are along the PC1 axis. Suggesting unique neural activities during this session.</span></p><p class="c12"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 702.50px; height: 561.77px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image11.png" style="width: 702.50px; height: 561.77px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c28 c14 c20">figure 15</span></p><p class="c9"><span class="c1">In figure 15, we notice mouse-specific clusters. We can see Forsmann forming a distinct cluster on the left. The clustering by mouse suggests that individual differences in mice considered for this experiment might cause variance in the neural activity being recorded. </span></p><p class="c9"><span class="c1">We see strong clustering by both session and mouse. This suggests that in developing the prediction model, we will need to account for both of these sources of variation. We can see that PC1 captures the largest variance in the data. This is likely due to mouse-specific or session-specific patterns. </span></p><p class="c9 c8"><span class="c1"></span></p><p class="c12"><span class="c0">V. Data Integration</span></p><p class="c12"><span class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c1">This is a vital step before developing our prediction model. Our goal here is to create a standardized dataset that would be suitable for predictive modeling. I implemented a comprehensive approach to integrate the neural activity data across all 18 sessions into a unified dataset that would be suitable for our prediction models. The steps for this process are: feature extraction, feature engineering, standardization, and dataset preparation.</span></p><p class="c12"><span class="c17 c14">Feature Extraction</span></p><p class="c9"><span class="c1">The first step involved extracting relevant features from each trial from all the sessions. Then, a unified dataset was created. There were a bunch of things that were extracted. First, we started with the basic session information, such as session ID, trial ID, mouse name, and the experiment date. Then, the stimulus features: left contrast, right contrast, and absolute contrast difference. This was then of course continued with the trial outcome/feedback type. It was recorded in 0&rsquo;s and 1&rsquo;s (1 for success and 0 for failure). Next, neural activity metrics were added to the dataset. That included, the mean firing rate across all neurons for each trial, decision-phase firing rate (focusing on time bins 10&ndash;30; corresponds to the critical decision-making period), peak firing rate with its corresponding time bin, and the average firing rate for each of the time bins. This resulted in a dataframe where each row represented a single trial with all its associated features, which we discussed above. </span></p><p class="c12"><span class="c17 c14">Feature Engineering</span></p><p class="c9"><span class="c1">To enhance the predictive accuracy of the models, additional features were engineered that could capture more complex patterns in the neural activity. First one is, firing rate slope. This is calculated as the rate of change in the neural activity during the decision phase. This could potentially indicate the dynamics of decision formation in the brains of the mice. The second feature is the early-to-late firing ratio. This will help in comparing the early decision-phase activity to the late decision-phase activity. This may reveal temporal patterns in decision-making. Next, we converted continuous contrast differences into categorical values such as very low, low, medium, and high. This was done to capture potential nonlinear effects. Lastly, we made mouse-specific and contrast-specific indicators. Variables for mouse identity and contrast categories to account for the individual variances and stimulus-specific effects. These features were designed to capture both temporal dynamics of neural activity and context factors that might also influence the decision-making outcomes. </span></p><p class="c12"><span class="c17 c14">Data Standardization</span></p><p class="c9"><span class="c1">To address the session-to-session variability, it was best if a session-specific standardization was implemented. The normalizing of numerical features ensured that each feature had 0 as the mean and unit variance within each session. The process made sure that the relative patterns within each session were preserved while making the data comparable across the sessions. This was a particularly important process given the PCA results. It revealed strong clustering by session and mouse. This indicated significant session-specific and mouse-specific variability.</span></p><p class="c12"><span class="c17 c14">Preparing the Dataset for Prediction Modeling</span></p><p class="c9"><span class="c1">For the final preparation of the model training and testing, I implemented a train-test split of 80-20 (80% training and 20% testing). Then, remove the no-predictive columns such as sesison_id, trial_id, date_exp. Lastly, the dataframe was converted into numpy arrays, which were compatible with machine learning algorithms. </span></p><p class="c12"><span class="c14 c42">Visualizing the Integrated Data.</span></p><p class="c12 c49"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 744.58px; height: 370.77px;"><img alt="" src="C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image8.png" style="width: 744.58px; height: 370.77px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c12"><span class="c28 c14 c20">figure 16 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;figure 17</span></p><p class="c12 c43"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 764.52px; height: 357.73px;"><img alt="" src="images/C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/images/image14.png" style="width: 764.52px; height: 357.73px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c12"><span class="c28 c14 c20">figure 18</span></p><p class="c9"><span class="c1">The integrated data visualizations in figures 16, 17 and 18 revealed important patterns as shown in the visualizations above. The boxplot in figure 16 demonstrates a clear difference in the mean of the firing rates between the successful and the failed trials. The successful trials, 1, show a higher firing rate compared to the failed trials, 0. This suggests that the level of neural activity is predictive of trial outcome. </span></p><p class="c9"><span class="c1">The histograms in figure 17 illustrate that successful trials are more frequent irrespective of the contrast difference. However, there is still a bias towards the idea of higher contras differences leading to better results. This reinforced the finding that we had from the EDA section, which was greater the contrast difference, easier the decision-making, and higher the success rates. </span></p><p class="c9"><span class="c1">The time series plot (figure 18) reveals divergent patterns in neural activity when it comes to successful and failed trials. Successful trials maintain a consistently higher firing rate during the decision-making phase (between the dashed line at 0.1 and 0.3). This might be a key predictor when it comes to trial outcomes. </span></p><p class="c9"><span class="c1">To conclude, this integrated dataset forms a solid foundation for building predictive models. This dataset provides the essential characteristics that distinguish successful trials from failed trials. This is because the dataset captures both the static features and the dynamic features.</span></p><p class="c12"><span class="c0">VI. Predictive Modeling</span></p><p class="c12"><span class="c41">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c14">Our goal here is to </span><span class="c14 c18">build a predictive model to predict the outcome (i.e., feedback type) of each trial using the neural activity data (i.e., spike trains in </span><span class="c14">spks</span><span class="c14 c18">), along with the stimuli (the left and right contrasts).</span><span class="c18 c52">&nbsp;</span><span class="c14">Following the comprehensive exploratory data analysis and data integration steps, we have classified the goal for this prediction task to the one of categorization. Therefore, the models that we have chosen are the ones intended for classification purposes, such as: logistic regression, xgboost, kNN classification, and random forest.</span></p><p class="c12"><span class="c17 c14">Evaluation Methodolody</span></p><p class="c12"><span class="c14">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A 4-fold cross-validation is implemented before we start developing prediction algorithms. As we saw from figure 17, there is a class imbalance (there are more successful trials than failed ones). For this, we used stratified folds. </span></p><p class="c12"><span class="c24">Model A: Logistic Regression on Average Spikes per Neuron</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As a baseline approach, a simple logistic regression model was implemented using only the average spikes per neuron as the predictor variable. This univariate model provides insight into the fact whether neural firing rate can be used alone to predict trial outcomes. </span></p><p class="c12"><span class="c17 c14">Methodology</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The logistic regression model was fitted using scikit-learn implementation. The first feature from the dataset was used. It represents the average neural firing rate across all neurons in a trial. The dataset we used contained 4,064 trials.</span></p><p class="c12"><span class="c17 c14">Results</span></p><p class="c9"><span class="c1">When evaluated on the test set, the model had poor performance. Here is the confusion matrix it produced: </span></p><table class="c29"><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6 c8"><span class="c1"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Predicted: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Predicted: Success</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">51</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">243</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Success</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">55</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">668</span></p></td></tr></table><p class="c12"><span class="c28 c14 c20">Table 6: confusion matrix for model A</span></p><p class="c12"><span class="c1">The model at hand predicted all trials as successes, failing to identify any failures. </span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It had a misclassification error rate of 29.3%. This reflects the the proportion of failure trials in the test set that were classified as success. Its AUC score was 0.6877. </span></p><p class="c12"><span class="c17 c14">Model Performance</span></p><p class="c40"><span class="c1">Logistic Regression Model Evaluation:</span></p><p class="c40"><span class="c1">Accuracy: 0.7070</span></p><p class="c40"><span class="c1">AUC Score: 0.6877</span></p><p class="c40"><span class="c1">F1 Score: 0.8176</span></p><p class="c40"><span class="c1">Log Loss: 0.5575</span></p><p class="c40"><span class="c14">Brier Score: 0.1891</span></p><p class="c12"><span class="c17 c14">Insights</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The average neural firing rate alone is insufficient for predicting trial outcomes. These results demonstrate the need for a more sophisticated model that can capture the complex patterns in the neural activity data that are related to decision-making outcomes. We can see that there is a bias towards predicting success as there are more successful trials. </span></p><p class="c12"><span class="c24">Model B: XGBoost Model for Predicting Feedback</span></p><p class="c12"><span class="c17 c14">Methodology</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Next, we will be using XGBoost classifier with 50 gradient-boosted trees. This is due to the imbalanced data that we have at hand. It can be used to capture nonlinear relationships. We train XGBoost on all available predictors in the dataset. This model was evaluated using the same test dataset, which was used for logistic regression.</span></p><p class="c12"><span class="c17 c14">Result</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The model demonstrated improved performance when compared to the logistic regression model. Here is the confusion matrix, which depicts the outcome with the same test data used.</span></p><table class="c29"><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6 c8"><span class="c1"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Predicted: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Predicted: Success</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">68</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">226</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Success</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">75</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">648</span></p></td></tr></table><p class="c12"><span class="c28 c14 c20">table 7: confusion matrix XGBoost</span></p><p class="c12"><span class="c1">This model was able to correctly identify 68 failure trials. Although it still misclassified 226 failures as successful trials. Its miclassification error rate is 29.6%. The model is overpredicting successes. To conclude, it has 70.4% accuracy.</span></p><p class="c12"><span class="c17 c14">Model Performance</span></p><p class="c12"><span class="c14">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The AUC score (area under the curve) is 0.7. This indicates a moderate prediction power. The closer AUC score is to 1, the better the predicting power. </span><span class="c14 c18">Average Metrics: {&#39;avg_accuracy&#39;: 0.6980807086614172, &#39;avg_precision&#39;: 0.7434401267230983, &#39;avg_recall&#39;: 0.8773792201163965, &#39;avg_f1&#39;: 0.8047371383940881, &#39;avg_auc&#39;: 0.6792560030534855}</span></p><p class="c12"><span class="c17 c14">Insights</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The XGBoost models demonstrate the importance of incorporating multiple features. There was a significant improvement in the AUC score. On the contrary, the model still misclassifies failure trials. This is evident with the high number of false positives that were reported. </span></p><p class="c12"><span class="c24">Model C: kNN Classification to Predict Feedback</span></p><p class="c12"><span class="c17 c14">Methodology </span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We identified the best k being k = 19 and trained the kNN classification model on the training data. This was done with the help of GridSearchCV with the parameter of interest being k. The model classifies each trial based on the majority label among its 19 closest neighbors. After training the data, tested it with our test data and made a confusion matrix.</span></p><table class="c29"><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6 c8"><span class="c1"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Predicted: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Predicted: Success</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">44</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">250</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Success</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">50</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">673</span></p></td></tr></table><p class="c12"><span class="c28 c14 c20">table 8: confusion matrix for kNN</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;673 trials were successful and were predicted as success by the model. 250 of them are false positives. 44 of them are true negatives and 50 of them are false negatives. The misclassification error rate was 29.50% so the accuracy rate was 70.5%. </span></p><p class="c12"><span class="c17 c14">Model performance</span></p><p class="c9"><span class="c14">The AUC score was </span><span class="c14 c18">0.6407</span><span class="c14">. This shows that the model does not have a high predictive power. These results indicate that while kNN captures some patterns in the data, it does not generalize well for the prediction part of the goal. </span><span class="c1 c18">Average Metrics: {&#39;avg_accuracy&#39;: 0.6924212598425197, &#39;avg_precision&#39;: 0.723220756506239, &#39;avg_recall&#39;: 0.9187615780149583, &#39;avg_f1&#39;: 0.8091279900502485, &#39;avg_auc&#39;: 0.6398019231935539}</span></p><p class="c9 c8"><span class="c1"></span></p><p class="c12"><span class="c24">Model D: Random Forest Classification</span></p><p class="c9"><span class="c1">Random forest was used due to its ability to handle complex, nonlinear relationships and its robustness against overfitting&mdash;particularly important given the results of our PCA analysis. </span></p><p class="c12"><span class="c17 c14">Methodology</span></p><p class="c12"><span class="c14 c42">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c1">We employed a systematic approach to model development. Firstly, we started with hyperparameter tuning. We used 5-fold cross-validation with GridSearchCV. All the parameter combinations were searched, which included different numbers of trees (n_estimators), tree depth (max_depth), and split criteria (min_samples_split and min_samples_leaf). In the end, the optimal parameter configuration came to be: n_estimators = 200, max_depth = 10, min_samples_split = 2, min_sample_leaf = 1. To ensure there is a robust evaluation for the variables identified earlier, we used 4-fold cross-validation on the entire dataset.</span></p><p class="c12"><span class="c17 c14">Model performance</span></p><p class="c23"><span class="c14 c34 c18">Average Metrics: {&#39;avg_accuracy&#39;: 0.7260396984208602, &#39;avg_precision&#39;: 0.7293429676167389, &#39;avg_recall&#39;: 0.9767791590376467, &#39;avg_f1&#39;: 0.8350595442380971, &#39;avg_auc&#39;: 0.7011512412782382}</span></p><p class="c12"><span class="c17 c14">Results</span></p><p class="c12"><span class="c1">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After training the model and running it on test data, we get the following results:</span></p><table class="c29"><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6 c8"><span class="c1"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Prediction: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Prediction: Success</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">33</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">261</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Success</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">12</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">711</span></p></td></tr></table><p class="c12"><span class="c28 c14 c20">table 9: random forest outcome</span></p><p class="c9"><span class="c1">Final accuracy: 73.2%. AUC score: 54.8%. Missclassification error: 26.8%. The model&rsquo;s ability to correctly classify 73.2% of the trials supports our earlier analysis that contrast differences influence the trial outcomes</span></p><p class="c12"><span class="c24">Model Selection</span></p><p class="c9"><span class="c1">To determine the best model for prediction, all the four models that were discussed above were evaluated. Each model was assessed using accuracy, AUC score, F1 score, precision, and recall. We used cross validation to ensure that there was robustness and prevent overfitting. Random forest has the highest accuracy score of 72.6% and F1 score. This made it the best overall performer. Logistic regression performed slightly worse. kNN and XGBoost performed similarly. Random forest also had the highest recall. It captured nearly all the success trials. It had the second-best precision after XGBoost.</span></p><p class="c12 c8"><span class="c1"></span></p><p class="c12"><span class="c16">VII. Prediction performance on test sets</span></p><p class="c9"><span class="c1">After running the external final test data, we get a confusion matrix and an auc score which can give us insights into how the prediction model performed on the 2 test files which were combined into one dataframe. </span></p><table class="c29"><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6 c8"><span class="c1"></span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Prediction: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Prediction: Success</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Failure</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">5</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">50</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">Actual: Success</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">6</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c6"><span class="c1">139</span></p></td></tr></table><p class="c12"><span class="c14">The test accuracy was 72% and AUC score was 0.7240 which depicts high prediction power in the model. </span></p><p class="c12"><span class="c0">VIII. Discussion and Conclusion</span></p><p class="c9"><span class="c1">This study investigated the relationship between neural activity patterns and decision-making outcomes in mice. They were engaged with visual discrimination tasks, through exploratory data analysis, data integration, and predictive modeling, we have gained vital insights regarding the underlying decision-making process and how it is impacted by various conditions. </span></p><p class="c9"><span class="c1">Our analysis revealed that there is a distinct pattern successful and failed trials follow, respectively. In successful trials, there was a consistent demonstration of high firing rates. This suggested that increased neural engagement led to successful trials/better results. The contrast difference between visual stimuli was also a significant factor that influenced the trial outcomes. Larger the contrast differences, higher the success rates. Clear visual distinctions led to better and more accurate decisions. We also observed significant variability when it came to mice. Not all of them had the same amount of success. Lederberg had the highest, and Cori had the lowest. Although all the mice showed improvement over time. This showed how neural processes adapt and become more efficient with repeated exposure to the same task. </span></p><p class="c9"><span class="c14">We then tested the data at hand with various prediction models, namely: logistic regression, XGBoost, kNN classification, and random forest. Our goal here was to </span><span class="c14 c18">build a predictive model to predict the outcome (i.e., feedback type) of each trial. </span><span class="c1">Random forest achieved the best performance among the models tested. It had a 72% accuracy on the test data that was provided. It had an AUC score of 0.7240 which indicated good discriminative ability. How can this be improved? I guess its now time to address the elephant in the room. The data had more successful trials than failed ones. This caused an imbalance which made most of the prediction models classify failed trials as successful ones and not the other way around. This could be a way to make this study better. Try to mitigate this imbalance at hand. However, this might be a good foundation for future study. </span></p><p class="c9 c8"><span class="c1"></span></p><p class="c9 c8"><span class="c1"></span></p><p class="c9 c8"><span class="c1"></span></p><p class="c9 c8"><span class="c1"></span></p><p class="c9 c8"><span class="c1"></span></p><p class="c12 c8"><span class="c1"></span></p><p class="c4"><span class="c0">Appendix</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">import rpy2.robjects as robjects</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import os</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1">import scipy.stats as stats</span></p><p class="c4"><span class="c1"># Define the path to the data folder</span></p><p class="c4"><span class="c1">data_path = r&quot;C:\Users\arshi\OneDrive\Desktop\Soha\STA 141A\STA 141A project\Data&quot;</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Function to read RDS file</span></p><p class="c4"><span class="c1">def read_rds(file_path):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; readRDS = robjects.r[&#39;readRDS&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return readRDS(file_path)</span></p><p class="c4"><span class="c1"># load all sessions</span></p><p class="c4"><span class="c1">sessions = []</span></p><p class="c4"><span class="c1">for i in range(1, 19):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; file_name = f&#39;session{i}.rds&#39;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; file_path = os.path.join(data_path, file_name)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; session_data = read_rds(file_path)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; sessions.append(session_data)</span></p><p class="c4"><span class="c1"># Initialize a list to store session summaries</span></p><p class="c4"><span class="c1">session_summaries = []</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Process each session</span></p><p class="c4"><span class="c1">for i in sessions:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Extract session metadata</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; mouse_name = i.rx2(&#39;mouse_name&#39;)[0]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; date_exp = i.rx2(&#39;date_exp&#39;)[0]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Extract neural data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; spks = i.rx2(&#39;spks&#39;) &nbsp;# Spike trains (list of matrices)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Convert R matrix to numpy array for the first trial</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; first_trial_spks = np.array(spks[0])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; n_neurons = first_trial_spks.shape[0] &nbsp;# Number of neurons (rows in the spike matrix)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; n_trials = len(spks) &nbsp;# Number of trials (length of the list)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Extract feedback data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; feedback_type = np.array(i.rx2(&#39;feedback_type&#39;)) &nbsp;# Feedback type (1 or -1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; success_rate = np.mean(feedback_type == 1) &nbsp;# Success rate</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Extract brain area data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; brain_area = np.array(i.rx2(&#39;brain_area&#39;)) &nbsp;# Convert to numpy array</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; n_brain_area = len(np.unique(brain_area)) &nbsp;# Number of unique brain areas</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Append session summary to the list</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; session_summaries.append({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &quot;mouse_name&quot;: mouse_name,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &quot;date_exp&quot;: date_exp,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &quot;n_brain_area&quot;: n_brain_area,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &quot;n_neurons&quot;: n_neurons,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &quot;n_trials&quot;: n_trials,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &quot;success_rate&quot;: success_rate</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; })</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Convert to DataFrame for easier analysis</span></p><p class="c4"><span class="c1">session_summary_df = pd.DataFrame(session_summaries)</span></p><p class="c4"><span class="c1"># Convert to DataFrame for easier analysis</span></p><p class="c4"><span class="c1">session_summary_df = pd.DataFrame(session_summaries)</span></p><p class="c4"><span class="c1">print(dict(session_data.items()))</span></p><p class="c4"><span class="c1">print(session_data.names)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp;# Initialize lists to store contrast data</span></p><p class="c4"><span class="c1">contrast_left = []</span></p><p class="c4"><span class="c1">contrast_right = []</span></p><p class="c4"><span class="c1">equal_contrast = 0</span></p><p class="c4"><span class="c1">nonequal_contrast = 0</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Extract contrast data from all sessions</span></p><p class="c4"><span class="c1">for session in sessions:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; left = session.rx2(&#39;contrast_left&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; right = session.rx2(&#39;contrast_right&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Append contrast values to the lists</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; contrast_left.extend(left)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; contrast_right.extend(right)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Count equal vs. non-equal contrasts</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; equal_contrast += np.sum(left == right)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; nonequal_contrast += np.sum(left != right)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Convert lists to numpy arrays for easier analysis</span></p><p class="c4"><span class="c1">contrast_left = np.array(contrast_left)</span></p><p class="c4"><span class="c1">contrast_right = np.array(contrast_right)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># 1. Distribution of contrast_left and contrast_right</span></p><p class="c4"><span class="c1">plt.figure(figsize=(14, 6))</span></p><p class="c4"><span class="c1"># Plot distribution of contrast_left</span></p><p class="c4"><span class="c1">plt.subplot(1, 2, 1)</span></p><p class="c4"><span class="c1">sns.histplot(contrast_left, bins=[0, 0.25, 0.5, 1], kde=False, color=&quot;blue&quot;, stat=&quot;probability&quot;)</span></p><p class="c4"><span class="c1">plt.title(&quot;Distribution of Left Contrast&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Left Contrast&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Probability&quot;)</span></p><p class="c4"><span class="c1">plt.xticks([0, 0.25, 0.5, 1])</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Plot distribution of contrast_right</span></p><p class="c4"><span class="c1">plt.subplot(1, 2, 2)</span></p><p class="c4"><span class="c1">sns.histplot(contrast_right, bins=[0, 0.25, 0.5, 1], kde=False, color=&quot;green&quot;, stat=&quot;probability&quot;)</span></p><p class="c4"><span class="c1">plt.title(&quot;Distribution of Right Contrast&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Right Contrast&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Probability&quot;)</span></p><p class="c4"><span class="c1">plt.xticks([0, 0.25, 0.5, 1])</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">plt.tight_layout()</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/right_contrast.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; format=&#39;png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bbox_inches=&#39;tight&#39;) </span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1"># 2. Frequency of equal vs. non-equal contrasts</span></p><p class="c4"><span class="c1">equal_not_equal = pd.DataFrame({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;Contrast Type&quot;: [&quot;Equal&quot;, &quot;Non-Equal&quot;],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;Count&quot;: [equal_contrast, nonequal_contrast]</span></p><p class="c4"><span class="c1">})</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">plt.figure(figsize=(8, 6))</span></p><p class="c4"><span class="c1">sns.barplot(x=&quot;Contrast Type&quot;, y=&quot;Count&quot;, data=equal_not_equal, palette=&quot;rocket&quot;)</span></p><p class="c4"><span class="c1">plt.title(&quot;Frequency of Equal vs. Non-Equal Contrasts&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Contrast Type&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Count&quot;)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/equa_non_equal.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; format=&#39;png&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Print counts for equal vs. non-equal contrasts</span></p><p class="c4"><span class="c1">print(&quot;Equal Contrast Counts:&quot;, equal_contrast)</span></p><p class="c4"><span class="c1">print(&quot;Non-Equal Contrast Counts:&quot;, nonequal_contrast)</span></p><p class="c4"><span class="c1"># Plot success rate per session</span></p><p class="c4"><span class="c1">plt.figure(figsize=(10, 5))</span></p><p class="c4"><span class="c1">sns.lineplot(data=session_summary_df, x=range(1, len(session_summary_df)+1), y=&#39;success_rate&#39;, marker=&#39;o&#39;)</span></p><p class="c4"><span class="c1">plt.title(&#39;Success Rate per Session&#39;)</span></p><p class="c4"><span class="c1">plt.xlabel(&#39;Session Number&#39;)</span></p><p class="c4"><span class="c1">plt.ylabel(&#39;Success Rate&#39;)</span></p><p class="c4"><span class="c1">plt.grid(True)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/success_rate.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; format=&#39;png&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1"># Histogram of success rates</span></p><p class="c4"><span class="c1">plt.figure(figsize=(7, 5))</span></p><p class="c4"><span class="c1">sns.histplot(session_summary_df[&#39;success_rate&#39;], kde=True, color=&#39;purple&#39;, bins=10)</span></p><p class="c4"><span class="c1">plt.title(&#39;Distribution of Success Rates Across Sessions&#39;)</span></p><p class="c4"><span class="c1">plt.xlabel(&#39;Success Rate&#39;)</span></p><p class="c4"><span class="c1">plt.ylabel(&#39;Frequency&#39;)</span></p><p class="c4"><span class="c1">plt.grid(True)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/success_dist.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; format=&#39;png&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1">mouse_success_rate = session_summary_df.groupby(&quot;mouse_name&quot;)[&quot;success_rate&quot;].mean()</span></p><p class="c4"><span class="c1">print(mouse_success_rate)</span></p><p class="c4"><span class="c1"># Show success rate per session for each mouse</span></p><p class="c4"><span class="c1">for mouse in session_summary_df[&quot;mouse_name&quot;].unique():</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; mouse_sessions = session_summary_df[session_summary_df[&quot;mouse_name&quot;] == mouse]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Mouse: {mouse}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(mouse_sessions[[&quot;date_exp&quot;, &quot;success_rate&quot;]])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(&quot;-&quot; * 40)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">contrast_data = []</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">for i in sessions:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; left_contrast = np.array(i.rx2(&#39;contrast_left&#39;)).flatten()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; right_contrast = np.array(i.rx2(&#39;contrast_right&#39;)).flatten()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; feedback_type = np.array(i.rx2(&#39;feedback_type&#39;)).flatten()</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; success_rates = [(1 if fb == 1 else 0) for fb in feedback_type]</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for lc, rc, sr in zip(left_contrast, right_contrast, success_rates):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; if isinstance(lc, (list, np.ndarray)): &nbsp;# Extract single value if it&#39;s still an array</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; lc = lc[0]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; if isinstance(rc, (list, np.ndarray)): &nbsp;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; rc = rc[0]</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; contrast_data.append({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;left_contrast&quot;: float(lc), </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;right_contrast&quot;: float(rc), </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;success_rate&quot;: sr</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; })</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">contrast_df = pd.DataFrame(contrast_data)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Ensure columns are numeric</span></p><p class="c4"><span class="c1">contrast_df[&quot;left_contrast&quot;] = contrast_df[&quot;left_contrast&quot;].astype(float)</span></p><p class="c4"><span class="c1">contrast_df[&quot;right_contrast&quot;] = contrast_df[&quot;right_contrast&quot;].astype(float)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Compute mean success rate</span></p><p class="c4"><span class="c1">contrast_success_rate = contrast_df.groupby([&quot;left_contrast&quot;, &quot;right_contrast&quot;]).success_rate.mean().reset_index()</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">heatmap_data = contrast_success_rate.pivot(index=&quot;left_contrast&quot;, columns=&quot;right_contrast&quot;, values=&quot;success_rate&quot;)</span></p><p class="c4"><span class="c1">plt.figure(figsize=(8, 6))</span></p><p class="c4"><span class="c1">sns.heatmap(heatmap_data, annot=True, cmap=&quot;coolwarm&quot;, fmt=&quot;.2f&quot;, cbar=True)</span></p><p class="c4"><span class="c1">plt.title(&quot;Success Rate by Contrast Conditions&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Right Contrast&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Left Contrast&quot;)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/heatmap.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; format=&#39;png&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1">firing_rates = np.random.exponential(scale=0.1, size=10000)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">plt.figure(figsize=(10, 5))</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Create histogram</span></p><p class="c4"><span class="c1">plt.hist(firing_rates, bins=100, color=&#39;red&#39;, alpha=0.6, edgecolor=&#39;black&#39;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Labels and title</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Firing Rate (spikes per time bin)&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Frequency&quot;)</span></p><p class="c4"><span class="c1">plt.title(&quot;Distribution of Neuronal Firing Rates&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Show grid for readability</span></p><p class="c4"><span class="c1">plt.grid(True, which=&quot;both&quot;, linestyle=&quot;--&quot;, linewidth=0.5)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/firing_rate_time.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1">time_bins = 40 &nbsp;</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Initialize accumulation variables</span></p><p class="c4"><span class="c1">avg_firing_success = np.zeros(time_bins)</span></p><p class="c4"><span class="c1">avg_firing_failure = np.zeros(time_bins)</span></p><p class="c4"><span class="c1">success_count = 0</span></p><p class="c4"><span class="c1">failure_count = 0</span></p><p class="c4"><span class="c1">avg_firing_success = np.zeros(time_bins)</span></p><p class="c4"><span class="c1">avg_firing_failure = np.zeros(time_bins)</span></p><p class="c4"><span class="c1">success_count = 0</span></p><p class="c4"><span class="c1">failure_count = 0</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Process each session</span></p><p class="c4"><span class="c1">for session in sessions:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; spks = session.rx2(&#39;spks&#39;) &nbsp;# List of spike matrices (neurons x time bins)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; feedback = np.array(session.rx2(&#39;feedback_type&#39;)) &nbsp;# Success (1) or Failure (-1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for trial_idx, trial_spikes in enumerate(spks):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; trial_spikes = np.array(trial_spikes) &nbsp;# Convert R matrix to NumPy</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; if trial_spikes.shape[1] &lt; time_bins:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp;# Skip trials with insufficient time bins</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Compute mean firing rate over neurons for this trial</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; firing_rate = np.mean(trial_spikes[:, :time_bins], axis=0)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; if feedback[trial_idx] == 1:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; avg_firing_success += firing_rate</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; success_count += 1</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; else:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; avg_firing_failure += firing_rate</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; failure_count += 1</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Normalize by the number of trials</span></p><p class="c4"><span class="c1">if success_count &gt; 0:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; avg_firing_success /= success_count</span></p><p class="c4"><span class="c1">if failure_count &gt; 0:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; avg_firing_failure /= failure_count</span></p><p class="c4"><span class="c1"># Plot firing rates over time</span></p><p class="c4"><span class="c1">plt.figure(figsize=(12, 6))</span></p><p class="c4"><span class="c1">plt.plot(range(time_bins), avg_firing_success, label=&quot;Success&quot;, color=&quot;green&quot;)</span></p><p class="c4"><span class="c1">plt.plot(range(time_bins), avg_firing_failure, label=&quot;Failure&quot;, color=&quot;red&quot;)</span></p><p class="c4"><span class="c1">plt.title(&quot;Neuron Activity Over Time (Success vs. Failure)&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Time Bin&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Average Firing Rate&quot;)</span></p><p class="c4"><span class="c1">plt.legend(title=&quot;Trial Outcome&quot;)</span></p><p class="c4"><span class="c1">plt.grid(True)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Save and show</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/activity_time.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1">from sklearn.decomposition import PCA</span></p><p class="c4"><span class="c1">from scipy.stats import pearsonr</span></p><p class="c4"><span class="c1"># Store firing rates and trial outcomes</span></p><p class="c4"><span class="c1">firing_rates = []</span></p><p class="c4"><span class="c1">success_labels = []</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">for session in sessions:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; spks = session.rx2(&#39;spks&#39;) &nbsp;# List of spike matrices (one per trial)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; feedback = np.array(session.rx2(&#39;feedback_type&#39;)) &nbsp;# Success (1) or failure (-1)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for trial_idx, trial_spikes in enumerate(spks):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; trial_spikes = np.array(trial_spikes) &nbsp;# Convert to numpy array</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; if trial_spikes.ndim == 2: &nbsp;# Ensure it&#39;s a 2D array (neurons x time bins)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; avg_firing = np.mean(trial_spikes, axis=1) &nbsp;# Average firing per neuron</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; firing_rates.append(avg_firing)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; success_labels.append(feedback[trial_idx])</span></p><p class="c4"><span class="c1"># Convert to DataFrame to handle variable neuron counts</span></p><p class="c4"><span class="c1">firing_rates_df = pd.DataFrame(firing_rates)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Drop neurons with too many missing values (if some trials had fewer neurons)</span></p><p class="c4"><span class="c1">firing_rates_df.dropna(axis=1, inplace=True)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Convert back to NumPy arrays</span></p><p class="c4"><span class="c1">firing_rates = firing_rates_df.to_numpy()</span></p><p class="c4"><span class="c1"># Ensure success_labels is a flat list of integers</span></p><p class="c4"><span class="c1">success_labels = np.array([int(label) if isinstance(label, (list, np.ndarray)) else label for label in success_labels])</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Compute correlation for each neuron</span></p><p class="c4"><span class="c1">correlations = [pearsonr(firing_rates[:, i], success_labels)[0] for i in range(firing_rates.shape[1])]</span></p><p class="c4"><span class="c1"># Plot correlation distribution</span></p><p class="c4"><span class="c1">plt.figure(figsize=(8, 6))</span></p><p class="c4"><span class="c1">sns.histplot(correlations, bins=20, kde=True, color=&#39;blue&#39;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Correlation Coefficient&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Frequency&quot;)</span></p><p class="c4"><span class="c1">plt.title(&quot;Distribution of Neuron-Outcome Correlations&quot;)</span></p><p class="c4"><span class="c1">plt.grid(True)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/neuron_outcome_corr.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1">plt.figure(figsize=(10, 6))</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Sort data by experiment date</span></p><p class="c4"><span class="c1">session_summary_df[&quot;date_exp&quot;] = pd.to_datetime(session_summary_df[&quot;date_exp&quot;])</span></p><p class="c4"><span class="c1">all_data = session_summary_df.sort_values(&#39;date_exp&#39;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Plot individual mice learning curves</span></p><p class="c4"><span class="c1">for mouse in all_data[&quot;mouse_name&quot;].unique():</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; mouse_data = all_data[all_data[&quot;mouse_name&quot;] == mouse]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.plot(range(len(mouse_data)), </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mouse_data[&quot;success_rate&quot;], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;marker=&quot;o&quot;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linestyle=&quot;-&quot;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;label=f&quot;Mouse {mouse}&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Compute and plot rolling average for all mice</span></p><p class="c4"><span class="c1">rolling_mean = all_data[&quot;success_rate&quot;].rolling(window=3, min_periods=1).mean()</span></p><p class="c4"><span class="c1">plt.plot(range(len(all_data)), </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;rolling_mean, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&#39;k--&#39;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;label=&quot;Overall Rolling Average&quot;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;linewidth=2)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Customize the plot</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Session Number&quot;, fontsize=12)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Success Rate&quot;, fontsize=12)</span></p><p class="c4"><span class="c1">plt.title(&quot;Learning Curves for Individual Mice&quot;, fontsize=14)</span></p><p class="c4"><span class="c1">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.7)</span></p><p class="c4"><span class="c1">plt.legend(bbox_to_anchor=(1.05, 1), loc=&quot;upper left&quot;)</span></p><p class="c4"><span class="c1">plt.tight_layout()</span></p><p class="c4"><span class="c1"># Save and show the plot</span></p><p class="c4"><span class="c1">plt.savefig(&quot;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/mouse_compare.png&quot;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&quot;png&quot;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Calculate learning improvement</span></p><p class="c4"><span class="c1">improvement_stats = all_data.groupby(&#39;mouse_name&#39;).agg({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &#39;success_rate&#39;: [</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; lambda x: x.iloc[-1] - x.iloc[0], &nbsp;# Total improvement</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; lambda x: (x.iloc[-1] - x.iloc[0]) / len(x) &nbsp;# Average improvement per session</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; ]</span></p><p class="c4"><span class="c1">}).round(3)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">improvement_stats.columns = [&#39;Total Improvement&#39;, &#39;Avg Improvement per Session&#39;]</span></p><p class="c4"><span class="c1">print(&quot;\nLearning Improvement Metrics:&quot;)</span></p><p class="c4"><span class="c1">print(improvement_stats)</span></p><p class="c4"><span class="c1">import rpy2.robjects as robjects</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">import os</span></p><p class="c4"><span class="c1"># Define the path to the data folder (use your actual path)</span></p><p class="c4"><span class="c1">data_path = r&quot;C:\Users\arshi\OneDrive\Desktop\Soha\STA 141A\STA 141A project\Data&quot;</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Function to read RDS file</span></p><p class="c4"><span class="c1">def read_rds(file_path):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; readRDS = robjects.r[&#39;readRDS&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return readRDS(file_path)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Initialize lists to store brain area data</span></p><p class="c4"><span class="c1">brain_area_data = []</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Process each session</span></p><p class="c4"><span class="c1">for i in range(1, 19):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; file_name = f&#39;session{i}.rds&#39;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; file_path = os.path.join(data_path, file_name)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; session = read_rds(file_path)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Extract session data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; mouse_name = session.rx2(&#39;mouse_name&#39;)[0]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; brain_areas = np.array(session.rx2(&#39;brain_area&#39;))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; spks = session.rx2(&#39;spks&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; feedback = np.array(session.rx2(&#39;feedback_type&#39;))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Calculate mean firing rate for each neuron across all trials</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; mean_firing_rates = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for trial_idx in range(len(spks)):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; trial_spks = np.array(spks[trial_idx])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; mean_firing_rates.append(np.mean(trial_spks, axis=1)) &nbsp;# average across time bins</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; mean_firing_rates = np.mean(mean_firing_rates, axis=0) &nbsp;# average across trials</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Store data for each neuron</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for i in range(len(brain_areas)):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; brain_area_data.append({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;mouse_name&#39;: mouse_name,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;brain_area&#39;: brain_areas[i],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;mean_firing_rate&#39;: mean_firing_rates[i],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;success_rate&#39;: np.mean(feedback == 1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; })</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1"># Convert collected data to a pandas DataFrame</span></p><p class="c4"><span class="c1">brain_df = pd.DataFrame(brain_area_data)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">plt.figure(figsize=(14, 10))</span></p><p class="c4"><span class="c1">sns.countplot(y=brain_df[&quot;brain_area&quot;], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; order=brain_df[&quot;brain_area&quot;].value_counts().index, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; color=&quot;blue&quot;) </span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Title and labels</span></p><p class="c4"><span class="c1">plt.title(&quot;Neuron Distribution Across Brain Areas&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Neuron Count&quot;, fontsize=14)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Brain Area&quot;, fontsize=14)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Improve tick labels</span></p><p class="c4"><span class="c1">plt.xticks(fontsize=12)</span></p><p class="c4"><span class="c1">plt.yticks(fontsize=10)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Adjust layout to prevent text overlap</span></p><p class="c4"><span class="c1">plt.tight_layout()</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/neuron_dis.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Show plot</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1"># 2. Firing Rate by Brain Area</span></p><p class="c4"><span class="c1">plt.figure(figsize=(12, 6))</span></p><p class="c4"><span class="c1">sns.boxplot(x=&quot;brain_area&quot;, y=&quot;mean_firing_rate&quot;, data=brain_df)</span></p><p class="c4"><span class="c1">plt.xticks(rotation=90) &nbsp;# Rotate x-axis labels if many brain areas</span></p><p class="c4"><span class="c1">plt.title(&quot;Mean Firing Rate by Brain Area&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Brain Area&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Mean Firing Rate&quot;)</span></p><p class="c4"><span class="c1">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.7)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/brain_box.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1"># 3. Success Rate by Brain Area</span></p><p class="c4"><span class="c1">plt.figure(figsize=(12, 6))</span></p><p class="c4"><span class="c1">sns.boxplot(x=&quot;brain_area&quot;, y=&quot;success_rate&quot;, data=brain_df, palette=&quot;magma&quot;)</span></p><p class="c4"><span class="c1">plt.xticks(rotation=90)</span></p><p class="c4"><span class="c1">plt.title(&quot;Success Rate by Brain Area&quot;)</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Brain Area&quot;)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Success Rate&quot;)</span></p><p class="c4"><span class="c1">plt.grid(True, linestyle=&quot;--&quot;, alpha=0.7)</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/rate_box.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1"># Convert to DataFrame</span></p><p class="c4"><span class="c1">brain_df = pd.DataFrame(brain_area_data)</span></p><p class="c4"><span class="c1">import statsmodels.api as sm</span></p><p class="c4"><span class="c1">import statsmodels.formula.api as smf</span></p><p class="c4"><span class="c1"># Prepare the data for ANOVA</span></p><p class="c4"><span class="c1">anova_data = []</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">for i in sessions:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; mouse_name = i.rx2(&#39;mouse_name&#39;)[0]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; contrast_left = np.array(i.rx2(&#39;contrast_left&#39;)).flatten()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; contrast_right = np.array(i.rx2(&#39;contrast_right&#39;)).flatten()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; feedback = np.array(i.rx2(&#39;feedback_type&#39;)).flatten()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; success_rates = [(1 if fb == 1 else 0) for fb in feedback]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; contrast_diffs = np.abs(contrast_left - contrast_right) &nbsp;# Compute contrast difference</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for diff, sr in zip(contrast_diffs, success_rates):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; anova_data.append({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;mouse_name&quot;: mouse_name,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contrast_diff&quot;: diff,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;success_rate&quot;: sr</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; })</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Convert to DataFrame</span></p><p class="c4"><span class="c1">anova_df = pd.DataFrame(anova_data)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Convert categorical variables to factors</span></p><p class="c4"><span class="c1">anova_df[&quot;mouse_name&quot;] = anova_df[&quot;mouse_name&quot;].astype(&quot;category&quot;)</span></p><p class="c4"><span class="c1">anova_df[&quot;contrast_diff&quot;] = anova_df[&quot;contrast_diff&quot;].astype(&quot;category&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Run the Two-Way ANOVA</span></p><p class="c4"><span class="c1">model = smf.ols(&quot;success_rate ~ C(mouse_name) + C(contrast_diff) + C(mouse_name):C(contrast_diff)&quot;, data=anova_df).fit()</span></p><p class="c4"><span class="c1">anova_table = sm.stats.anova_lm(model, typ=2) &nbsp;# Type 2 ANOVA Table</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Print results</span></p><p class="c4"><span class="c1">print(anova_table)</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Set up the figure</span></p><p class="c4"><span class="c1">plt.figure(figsize=(12, 8))</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Define better colors</span></p><p class="c4"><span class="c1">colors = [&quot;#3498db&quot;, &quot;#e67e22&quot;, &quot;#2ecc71&quot;, &quot;#e74c3c&quot;]</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Create the plot with basic enhancements and NO error bars</span></p><p class="c4"><span class="c1">ax = sns.pointplot(</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; x=&quot;contrast_diff&quot;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y=&quot;success_rate&quot;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; hue=&quot;mouse_name&quot;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; data=anova_df, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; ci=None,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; palette=colors,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; markers=[&quot;o&quot;, &quot;s&quot;, &quot;D&quot;, &quot;^&quot;],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; dodge=True</span></p><p class="c4"><span class="c1">)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Enhance appearance</span></p><p class="c4"><span class="c1">plt.xlabel(&quot;Contrast Difference&quot;, fontsize=14)</span></p><p class="c4"><span class="c1">plt.ylabel(&quot;Mean Success Rate&quot;, fontsize=14)</span></p><p class="c4"><span class="c1">plt.title(&quot;Interaction Plot: Contrast Difference vs. Success Rate by Mouse&quot;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; fontsize=16, pad=20)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Better legend</span></p><p class="c4"><span class="c1">plt.legend(title=&quot;Mouse Name&quot;, frameon=True)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Improved grid</span></p><p class="c4"><span class="c1">plt.grid(True, linestyle=&#39;--&#39;, alpha=0.7)</span></p><p class="c4"><span class="c1">plt.tight_layout()</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/interaction.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1">from statsmodels.stats.multicomp import pairwise_tukeyhsd</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Perform Tukey&#39;s HSD test for mouse_name</span></p><p class="c4"><span class="c1">tukey_mouse = pairwise_tukeyhsd(endog=anova_df[&quot;success_rate&quot;], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; groups=anova_df[&quot;mouse_name&quot;], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; alpha=0.05)</span></p><p class="c4"><span class="c1">print(tukey_mouse)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Perform Tukey&#39;s HSD test for contrast_diff</span></p><p class="c4"><span class="c1">tukey_contrast = pairwise_tukeyhsd(endog=anova_df[&quot;success_rate&quot;], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;groups=anova_df[&quot;contrast_diff&quot;], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;alpha=0.05)</span></p><p class="c4"><span class="c1">print(tukey_contrast)</span></p><p class="c4"><span class="c1">mport pandas as pd</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Initialize list for trial-wise firing rate data</span></p><p class="c4"><span class="c1">firing_data = []</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Process each session</span></p><p class="c4"><span class="c1">for session_idx, session in enumerate(sessions):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; spks = session.rx2(&#39;spks&#39;) &nbsp;# List of spike matrices</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; n_trials = len(spks)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for trial_id in range(n_trials):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; trial_spks = np.array(spks[trial_id]) &nbsp;# Neuron &times; Time spike data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; mean_spike = np.mean(trial_spks) &nbsp;# Compute mean spike rate across all neurons</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Append data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; firing_data.append({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;session_id&quot;: session_idx + 1,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;trial_id&quot;: trial_id + 1,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;mean_spike&quot;: mean_spike</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; })</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Convert to DataFrame</span></p><p class="c4"><span class="c1">firing_df = pd.DataFrame(firing_data)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Create FacetGrid plot</span></p><p class="c4"><span class="c1">g = sns.FacetGrid(firing_df, col=&quot;session_id&quot;, col_wrap=5, sharey=True, sharex=True, height=3.5)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Plot scatterplot for raw data (black dots)</span></p><p class="c4"><span class="c1">g.map(sns.scatterplot, &quot;trial_id&quot;, &quot;mean_spike&quot;, color=&quot;black&quot;, alpha=0.3)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Plot smooth trend line (gray)</span></p><p class="c4"><span class="c1">g.map(sns.lineplot, &quot;trial_id&quot;, &quot;mean_spike&quot;, color=&quot;gray&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Set consistent y-limits and tick marks</span></p><p class="c4"><span class="c1">y_min, y_max = firing_df[&quot;mean_spike&quot;].min(), firing_df[&quot;mean_spike&quot;].max()</span></p><p class="c4"><span class="c1">g.set(ylim=(y_min, y_max))</span></p><p class="c4"><span class="c1">g.set(yticks=np.linspace(y_min, y_max, 5)) &nbsp;# Set 5 tick marks on y-axis</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Adjust plot labels and titles</span></p><p class="c4"><span class="c1">g.set_axis_labels(&quot;Trial ID&quot;, &quot;Mean Spike Rate&quot;)</span></p><p class="c4"><span class="c1">g.set_titles(&quot;Session {col_name}&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Improve layout spacing to prevent labels from being cut off</span></p><p class="c4"><span class="c1">g.fig.subplots_adjust(hspace=0.3, wspace=0.3)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Save and show the plot</span></p><p class="c4"><span class="c1">plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/trends.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4"><span class="c1">plt.show()</span></p><p class="c4"><span class="c1">from sklearn.decomposition import PCA</span></p><p class="c4"><span class="c1">from sklearn.preprocessing import StandardScaler</span></p><p class="c4"><span class="c1"># Initialize lists to store features for PCA</span></p><p class="c4"><span class="c1">all_features = []</span></p><p class="c4"><span class="c1">session_ids = []</span></p><p class="c4"><span class="c1">mouse_names = []</span></p><p class="c4"><span class="c1">import rpy2.robjects as robjects</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import os</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1">from sklearn.decomposition import PCA</span></p><p class="c4"><span class="c1">from sklearn.preprocessing import StandardScaler</span></p><p class="c4"><span class="c1"># Define the path to the data folder</span></p><p class="c4"><span class="c1">data_path = r&quot;C:\Users\arshi\OneDrive\Desktop\Soha\STA 141A\STA 141A project\Data&quot;</span></p><p class="c4"><span class="c1"># Function to read RDS file</span></p><p class="c4"><span class="c1">def read_rds(file_path):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; readRDS = robjects.r[&#39;readRDS&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return readRDS(file_path)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Create NEW lists for PCA - make sure these are Python lists, not NumPy arrays</span></p><p class="c4"><span class="c1">pca_features = []</span></p><p class="c4"><span class="c1">pca_session_ids = []</span></p><p class="c4"><span class="c1">pca_mouse_names = []</span></p><p class="c4"><span class="c1"># Process each session for PCA</span></p><p class="c4"><span class="c1">for session_id in range(1, 19):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; try:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Load session data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; file_name = f&#39;session{session_id}.rds&#39;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; file_path = os.path.join(data_path, file_name)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; session = read_rds(file_path)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Extract session metadata</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; mouse_name = session.rx2(&#39;mouse_name&#39;)[0]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; spks = session.rx2(&#39;spks&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # For each trial in the session</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; for trial_idx in range(len(spks)):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Get spike data for this trial</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; trial_spks = np.array(spks[trial_idx])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Skip if there&#39;s no spike data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if trial_spks.size == 0:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Average firing rate across time bins for each neuron</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; neuron_mean_rates = np.mean(trial_spks, axis=1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Make sure we have data before appending</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if len(neuron_mean_rates) &gt; 0:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pca_features.append(neuron_mean_rates)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pca_session_ids.append(session_id)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pca_mouse_names.append(mouse_name)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; except Exception as e:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; print(f&quot;Error processing session {session_id}: {e}&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">print(f&quot;Collected data for {len(pca_features)} trials&quot;)</span></p><p class="c4"><span class="c1"># Process the collected data for PCA</span></p><p class="c4"><span class="c1">if len(pca_features) &gt; 0:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Find the maximum number of neurons in any trial</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; max_neurons = max(len(f) for f in pca_features)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Max neurons in any trial: {max_neurons}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Create a matrix where each row is a trial and each column is a neuron</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Pad with zeros if needed</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X = np.zeros((len(pca_features), max_neurons))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for i, features in enumerate(pca_features):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; X[i, :len(features)] = features</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Feature matrix shape: {X.shape}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Standardize the data</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; scaler = StandardScaler()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_scaled = scaler.fit_transform(X)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Apply PCA</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; pca = PCA(n_components=2)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; principal_components = pca.fit_transform(X_scaled)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Create a DataFrame for plotting - convert NumPy arrays after PCA</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; pca_df = pd.DataFrame({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;PC1&#39;: principal_components[:, 0],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;PC2&#39;: principal_components[:, 1],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;session_id&#39;: pca_session_ids, &nbsp;# Use the list directly</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;mouse_name&#39;: pca_mouse_names &nbsp; # Use the list directly</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; })</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Create the PCA plot by session</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.figure(figsize=(10, 8))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Plot with grid</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; sns.set_style(&quot;whitegrid&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; scatter = sns.scatterplot(</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; x=&#39;PC1&#39;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y=&#39;PC2&#39;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; hue=&#39;session_id&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; data=pca_df,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; palette=&#39;colorblind&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; alpha=0.7,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; s=50</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; )</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Add title and labels</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.title(&#39;PCA: PC1 vs PC2&#39;, fontsize=16)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.xlabel(&#39;PC1&#39;, fontsize=12)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.ylabel(&#39;PC2&#39;, fontsize=12)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Move legend outside plot</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.legend(bbox_to_anchor=(1.05, 1), loc=&#39;upper left&#39;, title=&#39;session_id&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Show explained variance</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; explained_variance = pca.explained_variance_ratio_</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Variance explained by PC1: {explained_variance[0]:.2%}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Variance explained by PC2: {explained_variance[1]:.2%}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Total variance explained: {sum(explained_variance):.2%}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.tight_layout()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/pca1.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.show()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Create the PCA plot by mouse</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.figure(figsize=(10, 8))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; sns.scatterplot(</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; x=&#39;PC1&#39;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y=&#39;PC2&#39;, </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; hue=&#39;mouse_name&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; data=pca_df,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; palette=&#39;viridis&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; alpha=0.7,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; s=50</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; )</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.title(&#39;PCA: PC1 vs PC2&#39;, fontsize=16)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.xlabel(&#39;PC1&#39;, fontsize=12)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.ylabel(&#39;PC2&#39;, fontsize=12)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.legend(bbox_to_anchor=(1.05, 1), loc=&#39;upper left&#39;, title=&#39;mouse_name&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.tight_layout()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/pca2.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.show()</span></p><p class="c4"><span class="c1">else:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(&quot;No data was collected. Check your file paths and data loading.&quot;)</span></p><p class="c4"><span class="c1"># setting up the environment and loading in the data</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">from sklearn.preprocessing import StandardScaler</span></p><p class="c4"><span class="c1">from sklearn.model_selection import train_test_split</span></p><p class="c4"><span class="c1">def create_unified_dataset(sessions):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Create a unified dataset from all sessions by extracting relevant features</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; from each trial.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; all_trials_data = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for session_idx, session in enumerate(sessions):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; n_trials = len(session.rx2(&#39;spks&#39;))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; n_neurons = len(session.rx2(&#39;brain_area&#39;))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; for trial_idx in range(n_trials):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Extract spikes data for this trial</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; spks = np.array(session.rx2(&#39;spks&#39;)[trial_idx])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Calculate features</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; time_bin_avgs = np.mean(spks, axis=0) &nbsp;# Average firing rate per time bin</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mean_firing_rate = np.mean(spks)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; decision_phase_rate = np.mean(spks[:, 10:30]) &nbsp;# Mean firing rate during decision-making phase</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; peak_firing_rate = np.max(np.mean(spks, axis=0)) &nbsp;# Peak firing rate</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; peak_time_bin = np.argmax(np.mean(spks, axis=0)) &nbsp;# Time bin of peak firing</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Create trial dictionary</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; trial_data = {</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;session_id&#39;: session_idx + 1,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;trial_id&#39;: trial_idx + 1,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;mouse_name&#39;: session.rx2(&#39;mouse_name&#39;)[0],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;date_exp&#39;: session.rx2(&#39;date_exp&#39;)[0],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;contrast_left&#39;: session.rx2(&#39;contrast_left&#39;)[trial_idx],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;contrast_right&#39;: session.rx2(&#39;contrast_right&#39;)[trial_idx],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;contrast_diff&#39;: abs(session.rx2(&#39;contrast_left&#39;)[trial_idx] - session.rx2(&#39;contrast_right&#39;)[trial_idx]),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;feedback_type&#39;: session.rx2(&#39;feedback_type&#39;)[trial_idx],</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;success&#39;: 1 if session.rx2(&#39;feedback_type&#39;)[trial_idx] == 1 else 0,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;mean_firing_rate&#39;: mean_firing_rate,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;decision_phase_rate&#39;: decision_phase_rate,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;peak_firing_rate&#39;: peak_firing_rate,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;peak_time_bin&#39;: peak_time_bin</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; # Add time bin averages</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for i, avg in enumerate(time_bin_avgs):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; trial_data[f&#39;time_bin_{i+1}&#39;] = avg</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; all_trials_data.append(trial_data)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Convert to DataFrame</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; df = pd.DataFrame(all_trials_data)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return df</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Create unified dataset</span></p><p class="c4"><span class="c1">unified_df = create_unified_dataset(sessions)</span></p><p class="c4"><span class="c1">def engineer_features(df):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Engineer additional features for the prediction model.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Calculate rate of change in firing (slope between early and late decision phase)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; df[&#39;firing_rate_slope&#39;] = (df[&#39;time_bin_30&#39;] - df[&#39;time_bin_10&#39;]) / 20</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Create a feature for early vs late firing ratio</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; df[&#39;early_late_ratio&#39;] = df[&#39;time_bin_10&#39;] / (df[&#39;time_bin_30&#39;] + 1e-10) &nbsp;# Add small value to avoid division by zero</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Categorize contrast differences</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; df[&#39;contrast_diff_cat&#39;] = pd.cut(df[&#39;contrast_diff&#39;], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;bins=[0, 0.25, 0.5, 0.75, 1.0], </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;labels=[&#39;very_low&#39;, &#39;low&#39;, &#39;medium&#39;, &#39;high&#39;])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # One-hot encode mouse names and sessions</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; df = pd.get_dummies(df, columns=[&#39;mouse_name&#39;], prefix=&#39;mouse&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; df = pd.get_dummies(df, columns=[&#39;contrast_diff_cat&#39;], prefix=&#39;contrast&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return df</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Apply feature engineering</span></p><p class="c4"><span class="c1">engineered_df = engineer_features(unified_df)</span></p><p class="c4"><span class="c1">all_feature_names = engineered_df.drop([&#39;session_id&#39;, &#39;trial_id&#39;, &#39;date_exp&#39;, &#39;feedback_type&#39;, &#39;success&#39;], axis=1).columns.tolist()</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Save these feature names for later use with test data</span></p><p class="c4"><span class="c1">np.save(&#39;feature_names.npy&#39;, all_feature_names)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># When processing test data:</span></p><p class="c4"><span class="c1">feature_names = np.load(&#39;feature_names.npy&#39;, allow_pickle=True)</span></p><p class="c4"><span class="c1">def standardize_features(df):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Standardize numerical features to have zero mean and unit variance.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Standardization is applied separately within each session to account for session-specific variations.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; sessions = df[&#39;session_id&#39;].unique()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; standardized_df = df.copy()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Identify numerical columns to standardize</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; time_bin_cols = [col for col in df.columns if col.startswith(&#39;time_bin_&#39;)]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; num_cols = [&#39;mean_firing_rate&#39;, &#39;decision_phase_rate&#39;, &#39;peak_firing_rate&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;firing_rate_slope&#39;, &#39;early_late_ratio&#39;] + time_bin_cols</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for session in sessions:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; session_mask = df[&#39;session_id&#39;] == session</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; scaler = StandardScaler()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Standardize numerical columns for this session</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; standardized_df.loc[session_mask, num_cols] = scaler.fit_transform(</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; df.loc[session_mask, num_cols]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; )</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return standardized_df</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Apply standardization</span></p><p class="c4"><span class="c1">standardized_df = standardize_features(engineered_df)</span></p><p class="c4"><span class="c1">standardized_df.head()</span></p><p class="c4"><span class="c1">standardized_df.info()</span></p><p class="c4"><span class="c1">def create_stratified_split(df, test_size=0.2, random_state=42):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Create a stratified train-test split that ensures representation from all sessions and mice.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; df[&#39;strat_col&#39;] = df[&#39;session_id&#39;].astype(str) + &#39;_&#39; + df[&#39;success&#39;].astype(str)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Drop strat_col before train-test split</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X = df.drop([&#39;feedback_type&#39;, &#39;success&#39;, &#39;strat_col&#39;], axis=1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y = df[&#39;success&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; strat_col = df[&#39;strat_col&#39;] &nbsp;# Store stratification column separately</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_train, X_test, y_train, y_test = train_test_split(</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; X, y, test_size=test_size, random_state=random_state, stratify=strat_col</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; )</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return X_train, X_test, y_train, y_test</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Create train-test split</span></p><p class="c4"><span class="c1">X_train, X_test, y_train, y_test = create_stratified_split(standardized_df)</span></p><p class="c4"><span class="c1">def prepare_final_datasets(X_train, X_test, y_train, y_test):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Prepare final datasets for modeling by removing non-feature columns.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Columns to drop (non-feature columns)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; cols_to_drop = [&#39;session_id&#39;, &#39;trial_id&#39;, &#39;date_exp&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Drop non-feature columns</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_train_final = X_train.drop(cols_to_drop, axis=1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_test_final = X_test.drop(cols_to_drop, axis=1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Convert to numpy arrays if needed</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_train_final = X_train_final.values</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_test_final = X_test_final.values</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y_train_final = y_train.values</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y_test_final = y_test.values</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return X_train_final, X_test_final, y_train_final, y_test_final</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Prepare final datasets</span></p><p class="c4"><span class="c1">X_train_final, X_test_final, y_train_final, y_test_final = prepare_final_datasets(X_train, X_test, y_train, y_test)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Save processed data for modeling</span></p><p class="c4"><span class="c1">np.save(&#39;X_train.npy&#39;, X_train_final)</span></p><p class="c4"><span class="c1">np.save(&#39;X_test.npy&#39;, X_test_final)</span></p><p class="c4"><span class="c1">np.save(&#39;y_train.npy&#39;, y_train_final)</span></p><p class="c4"><span class="c1">np.save(&#39;y_test.npy&#39;, y_test_final)</span></p><p class="c4"><span class="c1">def visualize_integrated_data(df):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Create visualizations of the integrated data for the report.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.figure(figsize=(12, 6))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Plot 1: Average firing rate by success vs failure</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.subplot(1, 2, 1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; sns.boxplot(x=&#39;success&#39;, y=&#39;mean_firing_rate&#39;, data=df)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.title(&#39;Average Firing Rate by Trial Outcome&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.xlabel(&#39;Success (1) vs Failure (0)&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.ylabel(&#39;Mean Firing Rate&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Plot 2: Contrast difference distribution by success vs failure</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.subplot(1, 2, 2)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; sns.histplot(data=df, x=&#39;contrast_diff&#39;, hue=&#39;success&#39;, multiple=&#39;dodge&#39;, bins=10)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.title(&#39;Contrast Difference by Trial Outcome&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.xlabel(&#39;Absolute Contrast Difference&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.ylabel(&#39;Count&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.tight_layout()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/integrated1.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.show() &nbsp;</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Plot firing rate across time bins for success vs failure</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.figure(figsize=(14, 6))</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Get time bin columns</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; time_bin_cols = [col for col in df.columns if col.startswith(&#39;time_bin_&#39;)]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; time_bin_cols.sort()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Create long-format DataFrame for time bins</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; time_bin_data = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for i, col in enumerate(time_bin_cols):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; time_bin = i + 1</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; for outcome in [0, 1]:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; subset = df[df[&#39;success&#39;] == outcome]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mean_val = subset[col].mean()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; time_bin_data.append({</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;time_bin&#39;: time_bin / 100, &nbsp;# Convert to seconds</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;mean_firing_rate&#39;: mean_val,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;outcome&#39;: &#39;Success&#39; if outcome == 1 else &#39;Failure&#39;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; })</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; time_bin_df = pd.DataFrame(time_bin_data)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Plot time bins</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; sns.lineplot(x=&#39;time_bin&#39;, y=&#39;mean_firing_rate&#39;, hue=&#39;outcome&#39;, data=time_bin_df)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.title(&#39;Average Firing Rate Across Time Bins by Trial Outcome&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.xlabel(&#39;Time (s)&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.ylabel(&#39;Mean Firing Rate&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.axvline(x=0.1, color=&#39;gray&#39;, linestyle=&#39;--&#39;, label=&#39;Decision Phase Start&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.axvline(x=0.3, color=&#39;gray&#39;, linestyle=&#39;--&#39;, label=&#39;Decision Phase End&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.legend()</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.savefig(&#39;C:/Users/arshi/OneDrive/Desktop/Soha/STA 141A/STA 141A project/time_bin_firing_rates.png&#39;,</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; dpi=300, format=&#39;png&#39;, bbox_inches=&#39;tight&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; plt.show()</span></p><p class="c4"><span class="c1">visualize_integrated_data(standardized_df)</span></p><p class="c4"><span class="c1">from sklearn.model_selection import KFold</span></p><p class="c4"><span class="c1">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">def perform_cross_validation(X, y, model, k=4):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Perform k-fold cross-validation and return performance metrics.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Parameters:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X : numpy array</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; Feature matrix</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y : numpy array</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; Target vector</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; model : scikit-learn model object</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; The model to evaluate</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; k : int, default=4</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; Number of folds for cross-validation</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Returns:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; dict</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; Dictionary containing performance metrics</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; kf = KFold(n_splits=k, shuffle=True, random_state=42)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; accuracy_scores = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; precision_scores = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; recall_scores = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; f1_scores = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; auc_scores = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; fold = 1</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for train_index, val_index in kf.split(X):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; X_train_fold, X_val_fold = X[train_index], X[val_index]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y_train_fold, y_val_fold = y[train_index], y[val_index]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Train the model</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; model.fit(X_train_fold, y_train_fold)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Predict</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y_pred = model.predict(X_val_fold)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y_prob = model.predict_proba(X_val_fold)[:, 1] if hasattr(model, &quot;predict_proba&quot;) else None</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Compute metrics</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; accuracy = accuracy_score(y_val_fold, y_pred)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; precision = precision_score(y_val_fold, y_pred)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; recall = recall_score(y_val_fold, y_pred)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; f1 = f1_score(y_val_fold, y_pred)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; auc = roc_auc_score(y_val_fold, y_prob) if y_prob is not None else None</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Store metrics</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; accuracy_scores.append(accuracy)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; precision_scores.append(precision)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; recall_scores.append(recall)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; f1_scores.append(f1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; if auc is not None:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; auc_scores.append(auc)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; print(f&quot;Fold {fold}: Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}, AUC={auc:.4f}&quot; if auc is not None else f&quot;Fold {fold}: Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; fold += 1</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Compute averages</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; avg_metrics = {</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;avg_accuracy&#39;: np.mean(accuracy_scores),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;avg_precision&#39;: np.mean(precision_scores),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;avg_recall&#39;: np.mean(recall_scores),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;avg_f1&#39;: np.mean(f1_scores),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;avg_auc&#39;: np.mean(auc_scores) if auc_scores else None</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; }</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;\nAverage Metrics: {avg_metrics}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return avg_metrics</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import matplotlib.pyplot as plt</span></p><p class="c4"><span class="c1">import seaborn as sns</span></p><p class="c4"><span class="c1">from sklearn.model_selection import train_test_split</span></p><p class="c4"><span class="c1">from sklearn.linear_model import LogisticRegression</span></p><p class="c4"><span class="c1">from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_recall_curve</span></p><p class="c4"><span class="c1">import xgboost as xgb</span></p><p class="c4"><span class="c1">import statsmodels.api as sm</span></p><p class="c4"><span class="c1">X_train = np.load(&#39;X_train.npy&#39;, allow_pickle=True)</span></p><p class="c4"><span class="c1">X_test = np.load(&#39;X_test.npy&#39;, allow_pickle=True)</span></p><p class="c4"><span class="c1">y_train = np.load(&#39;y_train.npy&#39;, allow_pickle=True)</span></p><p class="c4"><span class="c1">y_test = np.load(&#39;y_test.npy&#39;, allow_pickle=True)</span></p><p class="c4"><span class="c1"># Logistic Regression</span></p><p class="c4"><span class="c1">log_reg = LogisticRegression()</span></p><p class="c4"><span class="c1">log_reg_results = perform_cross_validation(X_train, y_train, log_reg, k=4)</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import statsmodels.api as sm</span></p><p class="c4"><span class="c1">from sklearn.linear_model import LogisticRegression</span></p><p class="c4"><span class="c1">from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score</span></p><p class="c4"><span class="c1">from sklearn.model_selection import KFold</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Function to perform k-fold cross-validation for Logistic Regression</span></p><p class="c4"><span class="c1">def logistic_regression_cross_val(X, y, k=4):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; kf = KFold(n_splits=k, shuffle=True, random_state=42)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; accuracy_scores = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; auc_scores = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; coefs = []</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for train_index, val_index in kf.split(X):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; X_train_fold, X_val_fold = X[train_index], X[val_index]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y_train_fold, y_val_fold = y[train_index], y[val_index]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Standard Logistic Regression using scikit-learn</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; log_reg = LogisticRegression(class_weight=&quot;balanced&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; log_reg.fit(X_train_fold, y_train_fold)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y_pred = log_reg.predict(X_val_fold)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; y_prob = log_reg.predict_proba(X_val_fold)[:, 1]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Compute Metrics</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; accuracy = accuracy_score(y_val_fold, y_pred)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; auc = roc_auc_score(y_val_fold, y_prob)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; accuracy_scores.append(accuracy)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; auc_scores.append(auc)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; # Store Coefficients</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; coefs.append(log_reg.coef_[0])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Convert coefficient list to numpy array</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; coefs = np.array(coefs)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;\nAverage Accuracy: {np.mean(accuracy_scores):.4f}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Average AUC Score: {np.mean(auc_scores):.4f}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return np.mean(accuracy_scores), np.mean(auc_scores), coefs</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Perform cross-validation</span></p><p class="c4"><span class="c1">log_reg_accuracy, log_reg_auc, log_reg_coefs = logistic_regression_cross_val(X_train, y_train)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Compute Parameter Estimates &amp; Standard Errors Using Statsmodels</span></p><p class="c4"><span class="c1">X_train_sm = sm.add_constant(X_train.astype(float)) &nbsp;# Add intercept</span></p><p class="c4"><span class="c1">X_train_sm = np.nan_to_num(X_train_sm, nan=np.nanmean(X_train_sm)) &nbsp;# Handle NaN</span></p><p class="c4"><span class="c1">logit_model = sm.Logit(y_train, X_train_sm).fit()</span></p><p class="c4"><span class="c1"># Print Logistic Regression Summary</span></p><p class="c4"><span class="c1">print(logit_model.summary())</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Extract Coefficients &amp; P-values</span></p><p class="c4"><span class="c1">print(f&quot;Coefficients: {logit_model.params}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;P-values: {logit_model.pvalues}&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Final Model Evaluation on Test Data</span></p><p class="c4"><span class="c1">log_reg_final = LogisticRegression()</span></p><p class="c4"><span class="c1">log_reg_final.fit(X_train, y_train)</span></p><p class="c4"><span class="c1">y_pred_final = log_reg_final.predict(X_test)</span></p><p class="c4"><span class="c1">y_prob_final = log_reg_final.predict_proba(X_test)[:, 1]</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Confusion Matrix &amp; Misclassification Error</span></p><p class="c4"><span class="c1">conf_matrix_final = confusion_matrix(y_test, y_pred_final)</span></p><p class="c4"><span class="c1">error_rate_final = 1 - accuracy_score(y_test, y_pred_final)</span></p><p class="c4"><span class="c1">auc_final = roc_auc_score(y_test, y_prob_final)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">print(f&quot;\nFinal Confusion Matrix:{conf_matrix_final}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Final Misclassification Error Rate: {error_rate_final:.4f}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Final AUC Score: {auc_final:.4f}&quot;)</span></p><p class="c4"><span class="c1">from xgboost import XGBClassifier</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># XGBoost Model</span></p><p class="c4"><span class="c1">xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=&#39;logloss&#39;)</span></p><p class="c4"><span class="c1">xgb_results = perform_cross_validation(X_train, y_train, xgb_model, k=4)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Fit model</span></p><p class="c4"><span class="c1">xgb_model.fit(X_train, y_train)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Predict on test data</span></p><p class="c4"><span class="c1">y_pred_xgb = xgb_model.predict(X_test)</span></p><p class="c4"><span class="c1">y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Confusion matrix &amp; misclassification error rate</span></p><p class="c4"><span class="c1">conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)</span></p><p class="c4"><span class="c1">error_rate_xgb = 1 - accuracy_score(y_test, y_pred_xgb)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">print(f&quot;Confusion Matrix (XGBoost):\n{conf_matrix_xgb}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Misclassification Error Rate (XGBoost): {error_rate_xgb:.4f}&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># AUC score</span></p><p class="c4"><span class="c1">auc_xgb = roc_auc_score(y_test, y_prob_xgb)</span></p><p class="c4"><span class="c1">print(f&quot;AUC Score (XGBoost): {auc_xgb:.4f}&quot;)</span></p><p class="c4"><span class="c1">from sklearn.neighbors import KNeighborsClassifier</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># KNN Model</span></p><p class="c4"><span class="c1">knn_model = KNeighborsClassifier(n_neighbors=19)</span></p><p class="c4"><span class="c1">knn_results = perform_cross_validation(X_train, y_train, knn_model, k=4)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Fit model</span></p><p class="c4"><span class="c1">knn_model.fit(X_train, y_train)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Predict on test data</span></p><p class="c4"><span class="c1">y_pred_knn = knn_model.predict(X_test)</span></p><p class="c4"><span class="c1">y_prob_knn = knn_model.predict_proba(X_test)[:, 1]</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Confusion matrix &amp; misclassification error rate</span></p><p class="c4"><span class="c1">conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)</span></p><p class="c4"><span class="c1">error_rate_knn = 1 - accuracy_score(y_test, y_pred_knn)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">print(f&quot;Confusion Matrix (KNN):\n{conf_matrix_knn}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Misclassification Error Rate (KNN): {error_rate_knn:.4f}&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># AUC score</span></p><p class="c4"><span class="c1">auc_knn = roc_auc_score(y_test, y_prob_knn)</span></p><p class="c4"><span class="c1">print(f&quot;AUC Score (KNN): {auc_knn:.4f}&quot;)</span></p><p class="c4"><span class="c1">from sklearn.ensemble import RandomForestClassifier</span></p><p class="c4"><span class="c1">from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score</span></p><p class="c4"><span class="c1">from sklearn.model_selection import GridSearchCV</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1"># Step 1: Define Hyperparameter Grid</span></p><p class="c4"><span class="c1">param_grid = {</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &#39;n_estimators&#39;: [50, 100, 200], &nbsp;# Number of trees</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &#39;max_depth&#39;: [5, 10, 15], &nbsp;# Tree depth</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &#39;min_samples_split&#39;: [2, 5], &nbsp;# Minimum samples to split</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &#39;min_samples_leaf&#39;: [1, 2] &nbsp;# Minimum samples per leaf</span></p><p class="c4"><span class="c1">}</span></p><p class="c4"><span class="c1"># Step 2: Initialize the Random Forest Model</span></p><p class="c4"><span class="c1">rf = RandomForestClassifier(random_state=42)</span></p><p class="c4"><span class="c1"># Step 3: Perform Grid Search Cross-Validation</span></p><p class="c4"><span class="c1">grid_search = GridSearchCV(rf, param_grid, cv=5, scoring=&#39;accuracy&#39;, n_jobs=-1)</span></p><p class="c4"><span class="c1">grid_search.fit(X_train, y_train)</span></p><p class="c4"><span class="c1"># Step 4: Get Best Parameters</span></p><p class="c4"><span class="c1">best_params = grid_search.best_params_</span></p><p class="c4"><span class="c1">print(f&quot;Best Parameters: {best_params}&quot;)</span></p><p class="c4"><span class="c1"># Step 5: Train Random Forest with Best Parameters</span></p><p class="c4"><span class="c1">rf_best = RandomForestClassifier(**best_params, random_state=42)</span></p><p class="c4"><span class="c1"># Step 6: Perform k-fold cross-validation on the ENTIRE dataset with your custom function</span></p><p class="c4"><span class="c1">X = np.vstack((X_train, X_test)) &nbsp;# Combine train and test data</span></p><p class="c4"><span class="c1">y = np.concatenate((y_train, y_test)) &nbsp;# Combine train and test labels</span></p><p class="c4"><span class="c1">cv_metrics = perform_cross_validation(X, y, rf_best, k=4)</span></p><p class="c4"><span class="c1"># Step 7: Train final model on all training data for testing purposes</span></p><p class="c4"><span class="c1">rf_best.fit(X_train, y_train)</span></p><p class="c4"><span class="c1"># Step 8: Make Predictions on test set</span></p><p class="c4"><span class="c1">y_pred_rf = rf_best.predict(X_test)</span></p><p class="c4"><span class="c1"># Step 9: Evaluate Performance on test set</span></p><p class="c4"><span class="c1">accuracy_rf = accuracy_score(y_test, y_pred_rf)</span></p><p class="c4"><span class="c1">conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)</span></p><p class="c4"><span class="c1">auc_rf = roc_auc_score(y_test, y_pred_rf)</span></p><p class="c4"><span class="c1">misclassification_error_rf = 1 - accuracy_rf &nbsp;# Misclassification error</span></p><p class="c4"><span class="c1">print(f&quot;\nFinal Test Set Performance:&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Random Forest Accuracy: {accuracy_rf:.4f}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Random Forest AUC Score: {auc_rf:.4f}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Random Forest Misclassification Error: {misclassification_error_rf:.4f}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;Confusion Matrix:{conf_matrix_rf}&quot;)</span></p><p class="c4"><span class="c1"># Step 10: Detailed Classification Report</span></p><p class="c4"><span class="c1">print(&quot;Classification Report:\n&quot;, classification_report(y_test, y_pred_rf))</span></p><p class="c4"><span class="c1">from sklearn.metrics import precision_recall_curve, roc_auc_score, f1_score, log_loss, brier_score_loss</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">def evaluate_model(model, X_test, y_test):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y_pred = model.predict(X_test)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y_prob = model.predict_proba(X_test)[:, 1] &nbsp;# Probability of positive class</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1">&nbsp; &nbsp; results = {</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;Accuracy&#39;: accuracy_score(y_test, y_pred),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;AUC Score&#39;: roc_auc_score(y_test, y_prob),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;F1 Score&#39;: f1_score(y_test, y_pred),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;Log Loss&#39;: log_loss(y_test, y_prob),</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &#39;Brier Score&#39;: brier_score_loss(y_test, y_prob)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; }</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return results</span></p><p class="c4"><span class="c1"># Evaluate Logistic Regression model</span></p><p class="c4"><span class="c1">log_reg_results = evaluate_model(log_reg_final, X_test, y_test)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Print the results</span></p><p class="c4"><span class="c1">print(&quot;\nLogistic Regression Model Evaluation:&quot;)</span></p><p class="c4"><span class="c1">for metric, value in log_reg_results.items():</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;{metric}: {value:.4f}&quot;)</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import pyreadr &nbsp;# For reading RDS files</span></p><p class="c4"><span class="c1">import os</span></p><p class="c4"><span class="c1">from sklearn.ensemble import RandomForestClassifier</span></p><p class="c4"><span class="c1">from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score</span></p><p class="c4"><span class="c1">import os</span></p><p class="c4"><span class="c1">import numpy as np</span></p><p class="c4"><span class="c1">import pandas as pd</span></p><p class="c4"><span class="c1">import rpy2.robjects as robjects</span></p><p class="c4"><span class="c1">from sklearn.ensemble import RandomForestClassifier</span></p><p class="c4"><span class="c1">from sklearn.preprocessing import StandardScaler</span></p><p class="c4"><span class="c1">from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Define test data path</span></p><p class="c4"><span class="c1">test_data_path = r&quot;C:\Users\arshi\OneDrive\Desktop\Soha\STA 141A\STA 141A project\Test Data&quot;</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Function to read RDS file</span></p><p class="c4"><span class="c1">def read_rds(file_path):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; readRDS = robjects.r[&#39;readRDS&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return readRDS(file_path)</span></p><p class="c4"><span class="c1"># Load test data files</span></p><p class="c4"><span class="c1">test_sessions = []</span></p><p class="c4"><span class="c1">for test_file in [&#39;test1.rds&#39;, &#39;test2.rds&#39;]:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; file_path = os.path.join(test_data_path, test_file)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; test_sessions.append(read_rds(file_path))</span></p><p class="c4"><span class="c1"># Process the test data using your predefined functions</span></p><p class="c4"><span class="c1"># Create unified dataset</span></p><p class="c4"><span class="c1">test_unified_df = create_unified_dataset(test_sessions)</span></p><p class="c4"><span class="c1">print(f&quot;Unified test dataset shape: {test_unified_df.shape}&quot;)</span></p><p class="c4"><span class="c1"># Apply feature engineering</span></p><p class="c4"><span class="c1">test_engineered_df = engineer_features(test_unified_df)</span></p><p class="c4"><span class="c1">print(f&quot;Engineered test dataset shape: {test_engineered_df.shape}&quot;)</span></p><p class="c4"><span class="c1"># Apply standardization</span></p><p class="c4"><span class="c1">test_standardized_df = standardize_features(test_engineered_df)</span></p><p class="c4"><span class="c1">print(f&quot;Standardized test dataset shape: {test_standardized_df.shape}&quot;)</span></p><p class="c4"><span class="c1"># Prepare test data for model prediction</span></p><p class="c4"><span class="c1"># Since we&#39;re not splitting the test data, we&#39;ll modify the prepare_final_datasets function</span></p><p class="c4"><span class="c1">def prepare_test_dataset(df):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Prepare test dataset for prediction by removing non-feature columns.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Columns to drop (non-feature columns)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; cols_to_drop = [&#39;session_id&#39;, &#39;trial_id&#39;, &#39;date_exp&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Extract the target variable</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y_test = df[&#39;success&#39;]</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Drop non-feature columns and target variable</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_test = df.drop(cols_to_drop + [&#39;success&#39;, &#39;feedback_type&#39;], axis=1)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return X_test, y_test</span></p><p class="c4"><span class="c1"># Prepare test dataset</span></p><p class="c4"><span class="c1">X_test_external, y_test_external = prepare_test_dataset(test_standardized_df)</span></p><p class="c4"><span class="c1">print(f&quot;External test features shape: {X_test_external.shape}&quot;)</span></p><p class="c4"><span class="c1">print(f&quot;External test target shape: {y_test_external.shape}&quot;)</span></p><p class="c4"><span class="c1"># Check if test data is loaded</span></p><p class="c4"><span class="c1">print(test_standardized_df.head()) &nbsp;# Preview the first few rows</span></p><p class="c4"><span class="c1">print(test_standardized_df.columns) &nbsp;# Check column names</span></p><p class="c4"><span class="c1"># For your test data processing</span></p><p class="c4"><span class="c1">def prepare_test_dataset(test_df, feature_names):</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; Prepare test dataset with the same features as training data.</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &quot;&quot;&quot;</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Process test data </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; test_df = engineer_features(test_df)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; test_df = standardize_features(test_df)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Extract target</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; y_test = test_df[&#39;success&#39;] if &#39;success&#39; in test_df.columns else None</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Drop non-feature columns</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; test_df = test_df.drop([&#39;session_id&#39;, &#39;trial_id&#39;, &#39;date_exp&#39;, &#39;feedback_type&#39;, &#39;success&#39;], axis=1, errors=&#39;ignore&#39;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Ensure all required features are present</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; for feature in feature_names:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; if feature not in test_df.columns:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; test_df[feature] = 0 &nbsp;# Add missing columns with default value</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Keep only the features used in training</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; X_test = test_df[feature_names].values</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; return X_test, y_test</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># When processing test data:</span></p><p class="c4"><span class="c1">X_test_external, y_test_external = prepare_test_dataset(test_unified_df, feature_names)</span></p><p class="c4"><span class="c1"># Now that your test data is correctly formatted, make predictions</span></p><p class="c4"><span class="c1">y_pred_rf = rf_best.predict(X_test_external)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># Get prediction probabilities (optional)</span></p><p class="c4"><span class="c1">y_pred_proba_rf = rf_best.predict_proba(X_test_external)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c4"><span class="c1"># If you have ground truth labels for test data, evaluate performance</span></p><p class="c4"><span class="c1">if y_test_external is not None:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Calculate accuracy</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; accuracy = accuracy_score(y_test_external, y_pred_rf)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(f&quot;Test accuracy: {accuracy:.4f}&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Create confusion matrix</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; cm = confusion_matrix(y_test_external, y_pred_rf)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(&quot;Confusion Matrix:&quot;)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; print(cm)</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; </span></p><p class="c4"><span class="c1">&nbsp; &nbsp; # Calculate AUC-ROC if applicable</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; if y_pred_proba_rf is not None and len(np.unique(y_test_external)) == 2:</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; auc_roc = roc_auc_score(y_test_external, y_pred_proba_rf[:, 1])</span></p><p class="c4"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; print(f&quot;AUC-ROC: {auc_roc:.4f}&quot;)</span></p><p class="c4 c8"><span class="c1"></span></p><p class="c8 c19"><span class="c1"></span></p><p class="c19 c8"><span class="c1"></span></p></body></html>